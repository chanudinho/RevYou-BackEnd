@article{Hoda201760,
title = "Systematic literature reviews in agile software development: A tertiary study ",
journal = "Information and Software Technology ",
volume = "85",
number = "",
pages = "60 - 70",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.01.007",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917300538",
author = "Rashina Hoda and Norsaremah Salleh and John Grundy and Hui Mien Tee",
keywords = "Agile software development",
keywords = "Tertiary study",
keywords = "Systematic literature reviews",
keywords = "Mapping study ",
abstract = "AbstractContext A number of systematic literature reviews and mapping studies (SLRs) covering numerous primary research studies on various aspects of agile software development (ASD) exist. Objective The aim of this paper is to provide an overview of the \{SLRs\} on \{ASD\} research topics for software engineering researchers and practitioners. Method We followed the tertiary study guidelines by Kitchenham et al. to find \{SLRs\} published between late 1990s to December 2015. Results We found 28 \{SLRs\} focusing on ten different \{ASD\} research areas: adoption, methods, practices, human and social aspects, CMMI, usability, global software engineering (GSE), organizational agility, embedded systems, and software product line engineering. The number of \{SLRs\} on \{ASD\} topics, similar to those on software engineering (SE) topics in general, is on the rise. A majority of the \{SLRs\} applied standardized guidelines and the quality of these \{SLRs\} on \{ASD\} topics was found to be slightly higher for journal publications than for conferences. While some individuals and institutions seem to lead this area, the spread of authors and institutions is wide. With respect to prior review recommendations, significant progress was noticed in the area of connecting agile to established domains such as usability, CMMI, and GSE; and considerable progress was observed in focusing on management-oriented approaches as Scrum and sustaining \{ASD\} in different contexts such as embedded systems. Conclusion \{SLRs\} of \{ASD\} studies are on the rise and cover a variety of \{ASD\} aspects, ranging from early adoption issues to newer applications of \{ASD\} such as in product line engineering. \{ASD\} research can benefit from further primary and secondary studies on evaluating benefits and challenges of \{ASD\} methods, agile hybrids in large-scale setups, sustainability, motivation, teamwork, and project management; as well as a fresh review of empirical studies in \{ASD\} to cover the period post 2008. "
}
@article{Garousi2016195,
title = "A systematic literature review of literature reviews in software testing ",
journal = "Information and Software Technology ",
volume = "80",
number = "",
pages = "195 - 216",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2016.09.002",
url = "https://www.sciencedirect.com/science/article/pii/S0950584916301446",
author = "Vahid Garousi and Mika V. Mäntylä",
keywords = "Secondary studies",
keywords = "Tertiary study",
keywords = "Software testing",
keywords = "Systematic mapping",
keywords = "Systematic literature reviews",
keywords = "Surveys ",
abstract = "AbstractContext Any newcomer or industrial practitioner is likely to experience difficulties in digesting large volumes of knowledge in software testing. In an ideal world, all knowledge used in industry, education and research should be based on high-quality evidence. Since no decision should be made based on a single study, secondary studies become essential in presenting the evidence. According to our search, over 101 secondary studies have been published in the area of software testing since 1994. With this high number of secondary studies, it is important to conduct a review in this area to provide an overview of the research landscape in this area. Objective The goal of this study is to systematically map (classify) the secondary studies in software testing. We propose that tertiary studies can serve as summarizing indexes which facilitate finding the most relevant information from secondary studies and thus supporting evidence-based decision making in any given area of software engineering. Our research questions (RQs) investigate: (1) Software-testing-specific areas, (2) Types of \{RQs\} investigated, (3) Numbers and Trends, and (4) Citations of the secondary studies. Method To conduct the tertiary study, we use the systematic-mapping approach. Additionally, we contrast the testing topics to the number of Google hits to address a general popularity of a testing topic and study the most popular papers in terms of citations. We furthermore demonstrate the practicality and usefulness of our results by mapping them to \{ISTQB\} foundation syllabus and to \{SWEBOK\} to provide implications for practitioners, testing educators, and researchers. Results After a systematic search and voting process, our study pool included 101 secondary studies in the area of software testing between 1994 and 2015. Among our results are the following: (1) In terms of number of secondary studies, model-based approach is the most popular testing method, web services are the most popular system under test (SUT), while regression testing is the most popular testing phase; (2) The quality of secondary studies, as measured by a criteria set established in the community, is slowly increasing as the years go by; and (3) Analysis of research questions, raised and studied in the pool of secondary studies, showed that there is a lack of ‘causality’ and ‘relationship’ type of research questions, a situation which needs to be improved if we, as a community, want to advance as a scientific field. (4) Among secondary studies, we found that regular surveys receive significantly more citations than \{SMs\} (p = 0.009) and \{SLRs\} (p = 0.014). Conclusion Despite the large number of secondary studies, we found that many important areas of software testing currently lack secondary studies, e.g., test management, role of product risk in testing, human factors in software testing, beta-testing (A/B-testing), exploratory testing, testability, test stopping criteria, and test-environment development. Having secondary studies in those areas is important for satisfying industrial and educational needs in software testing. On the other hand, education material of \{ISTQB\} foundation syllabus and \{SWEBOK\} could benefit from the inclusion of the latest research topics, namely search-based testing, use of cloud-computing for testing and symbolic execution. "
}
@article{Petersen20151,
title = "Guidelines for conducting systematic mapping studies in software engineering: An update ",
journal = "Information and Software Technology ",
volume = "64",
number = "",
pages = "1 - 18",
year = "2015",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.03.007",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915000646",
author = "Kai Petersen and Sairam Vakkalanka and Ludwik Kuzniarz",
keywords = "Systematic mapping studies",
keywords = "Software engineering",
keywords = "Guidelines ",
abstract = "AbstractContext Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and \{SLR\} guidelines. Objective To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly. Method We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment). Results In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given. Conclusion The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings. "
}
@article{khan2018156,
title = "Empirical studies omit reporting necessary details: A systematic literature review of reporting quality in model based testing ",
journal = "Computer Standards & Interfaces ",
volume = "55",
number = "",
pages = "156 - 170",
year = "2018",
note = "",
issn = "0920-5489",
doi = "https://doi.org/10.1016/j.csi.2017.08.002",
url = "https://www.sciencedirect.com/science/article/pii/S0920548916302112",
author = "Muhammad Uzair khan and Sidra iftikhar and Muhammad Zohaib Iqbal and Salman Sherin",
keywords = "Empirical study",
keywords = "Reporting quality",
keywords = "Reporting guidelines",
keywords = "Model based testing ",
abstract = "AbstractContext Empirical studies are essential in evaluating the effectiveness of Model-based Testing (MBT) research and should be reported properly to ensure their replication and to highlight the strengths and limitations of the \{MBT\} techniques being evaluated. Researchers have proposed guidelines detailing what information should be reported when presenting empirical studies and what should be the structure of such primary studies. There is a need to evaluate the reporting quality of the empirical studies in \{MBT\} literature. Objective To evaluate the reporting quality of empirical studies in the model based testing domain; identifying where the reported studies fail to follow the proposed guidelines and finding frequently omitted details. As an auxiliary goal we aim to quantify the percentage of empirical studies conducted in industrial context. Method We evaluate the reporting quality and the execution contexts of \{MBT\} empirical studies reported in literature. For our study we consider the \{MBT\} papers published in top ten software engineering journals over the last eighteen years. We evaluate the published primary studies using the empirical study reporting guidelines. Results We found 87 empirical in \{MBT\} that met our selection criteria. Initial results showed that the existing guidelines were not only too strict (for example they demand presence of specific sections rather than simply having the details present in the paper), they also did not adequately cover \{MBT\} specific details. Therefore, we propose modified the guidelines for reporting empirical studies in \{MBT\} and re-evaluated the selected studies. Results show that while only a few empirical studies follow the exact structure proposed by the guidelines, approximately half the papers contain at least 50% of the required details. Most of the papers omit details related to process and analysis leading to presented results. We found a positive trend of improving reporting quality of empirical studies in \{MBT\} over the last Eighteen years. Another important finding from the review is that few reported studies were conducted in real industrial context. Conclusions Model based testing community needs to be more aware of the reporting guidelines and more effort should be spent on reporting the necessary details. Furthermore, we found that only few studies that are conducted in industrial context and hence more focus should be given to empirical case studies in real industry context. However, the reporting quality of research papers presenting empirical evaluations is gradually improving. "
}
@article{Budgen2018234,
title = "The contribution that empirical studies performed in industry make to the findings of systematic reviews: A tertiary study ",
journal = "Information and Software Technology ",
volume = "94",
number = "",
pages = "234 - 244",
year = "2018",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.10.012",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917303798",
author = "David Budgen and Pearl Brereton and Nikki Williams and Sarah Drummond",
keywords = "Systematic review",
keywords = "Primary study",
keywords = "Industry study",
keywords = "Case study ",
abstract = "AbstractContext Systematic reviews can provide useful knowledge for software engineering practice, by aggregating and synthesising empirical studies related to a specific topic. Objective We sought to assess how far the findings of systematic reviews addressing practice-oriented topics have been derived from empirical studies that were performed in industry or that used industry data. Method We drew upon and augmented the data obtained from a tertiary study that performed a systematic review of systematic reviews published in the period up to the end of 2015, seeking to identify those with findings that are relevant for teaching and practice. For the supplementary analysis reported here, we then examined the profiles of the primary studies as reported in each systematic review. Results We identified 48 systematic reviews as candidates for further analysis. The many differences that arise between systematic reviews, together with the incompleteness of reporting for these, mean that our counts should be treated as indicative rather than definitive. However, even when allowing for problems of classification, the findings from the majority of these systematic reviews were predominantly derived from using primary studies conducted in industry. There was also an emphasis upon the use of case studies, and a number of the systematic reviews also made some use of weaker ‘experience’ or even ‘opinion’ papers. Conclusions Primary studies from industry play an important role as inputs to systematic reviews. Using more rigorous industry-based primary studies can give greater authority to the findings of the systematic reviews, and should help with the creation of a corpus of sound empirical data to support evidence-informed decisions. "
}
@article{Budgen2017,
title = "Reporting systematic reviews: Some lessons from a tertiary study ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.10.017",
url = "https://www.sciencedirect.com/science/article/pii/S0950584916303548",
author = "David Budgen and Pearl Brereton and Sarah Drummond and Nikki Williams",
keywords = "Systematic review",
keywords = "Reporting quality",
keywords = "Provenance of findings ",
abstract = "AbstractContext Many of the systematic reviews published in software engineering are related to research or methodological issues and hence are unlikely to be of direct benefit to practitioners or teachers. Those that are relevant to practice and teaching need to be presented in a form that makes their findings usable with minimum interpretation. Objective We have examined a sample of the many systematic reviews that have been published over a period of six years, in order to assess how well these are reported and identify useful lessons about how this might be done. Method We undertook a tertiary study, performing a systematic review of systematic reviews. Our study found 178 systematic reviews published in a set of major software engineering journals over the period 2010–2015. Of these, 37 provided recommendations or conclusions of relevance to education and/or practice and we used the \{DARE\} criteria as well as other attributes related to the systematic review process to analyse how well they were reported. Results We have derived a set of 12 ‘lessons’ that could help authors with reporting the outcomes of a systematic review in software engineering. We also provide an associated checklist for use by journal and conference referees. Conclusion There are several areas where better reporting is needed, including quality assessment, synthesis, and the procedures followed by the reviewers. Researchers, practitioners, teachers and journal referees would all benefit from better reporting of systematic reviews, both for clarity and also for establishing the provenance of any findings. "
}
@article{daSilva2011899,
title = "Six years of systematic literature reviews in software engineering: An updated tertiary study ",
journal = "Information and Software Technology ",
volume = "53",
number = "9",
pages = "899 - 913",
year = "2011",
note = "Studying work practices in Global Software Engineering ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2011.04.004",
url = "https://www.sciencedirect.com/science/article/pii/S0950584911001017",
author = "Fabio Q.B. da Silva and André L.M. Santos and Sérgio Soares and A. César C. França and Cleviton V.F. Monteiro and Felipe Farias Maciel",
keywords = "Systematic reviews",
keywords = "Mapping studies",
keywords = "Software engineering",
keywords = "Tertiary studies ",
abstract = "Context Since the introduction of evidence-based software engineering in 2004, systematic literature review (SLR) has been increasingly used as a method for conducting secondary studies in software engineering. Two tertiary studies, published in 2009 and 2010, identified and analysed 54 \{SLRs\} published in journals and conferences in the period between 1st January 2004 and 30th June 2008. Objective In this article, our goal was to extend and update the two previous tertiary studies to cover the period between 1st July 2008 and 31st December 2009. We analysed the quality, coverage of software engineering topics, and potential impact of published \{SLRs\} for education and practice. Method We performed automatic and manual searches for \{SLRs\} published in journals and conference proceedings, analysed the relevant studies, and compared and integrated our findings with the two previous tertiary studies. Results We found 67 new \{SLRs\} addressing 24 software engineering topics. Among these studies, 15 were considered relevant to the undergraduate educational curriculum, and 40 appeared of possible interest to practitioners. We found that the number of \{SLRs\} in software engineering is increasing, the overall quality of the studies is improving, and the number of researchers and research organisations worldwide that are conducting \{SLRs\} is also increasing and spreading. Conclusion Our findings suggest that the software engineering research community is starting to adopt \{SLRs\} consistently as a research method. However, the majority of the \{SLRs\} did not evaluate the quality of primary studies and fail to provide guidelines for practitioners, thus decreasing their potential impact on software engineering practice. "
}
@article{Soualhia2017170,
title = "Task Scheduling in Big Data Platforms: A Systematic Literature Review ",
journal = "Journal of Systems and Software ",
volume = "134",
number = "",
pages = "170 - 189",
year = "2017",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2017.09.001",
url = "https://www.sciencedirect.com/science/article/pii/S0164121217301954",
author = "Mbarka Soualhia and Foutse Khomh and Sofiène Tahar",
keywords = "Task Scheduling",
keywords = "Hadoop",
keywords = "Spark",
keywords = "Storm",
keywords = "Mesos",
keywords = "Systematic Literature Review ",
abstract = "Abstract Context: Hadoop, Spark, Storm, and Mesos are very well known frameworks in both research and industrial communities that allow expressing and processing distributed computations on massive amounts of data. Multiple scheduling algorithms have been proposed to ensure that short interactive jobs, large batch jobs, and guaranteed-capacity production jobs running on these frameworks can deliver results quickly while maintaining a high throughput. However, only a few works have examined the effectiveness of these algorithms. Objective: The Evidence-based Software Engineering (EBSE) paradigm and its core tool, i.e., the Systematic Literature Review (SLR), have been introduced to the Software Engineering community in 2004 to help researchers systematically and objectively gather and aggregate research evidences about different topics. In this paper, we conduct a \{SLR\} of task scheduling algorithms that have been proposed for big data platforms. Method: We analyse the design decisions of different scheduling models proposed in the literature for Hadoop, Spark, Storm, and Mesos over the period between 2005 and 2016. We provide a research taxonomy for succinct classification of these scheduling models. We also compare the algorithms in terms of performance, resources utilization, and failure recovery mechanisms. Results: Our searches identifies 586 studies from journals, conferences and workshops having the highest quality in this field. This \{SLR\} reports about different types of scheduling models (dynamic, constrained, and adaptive) and the main motivations behind them (including data locality, workload balancing, resources utilization, and energy efficiency). A discussion of some open issues and future challenges pertaining to improving the current studies is provided. "
}
@article{Vallon2017,
title = "Systematic literature review on agile practices in global software development ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.12.004",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917302975",
author = "Raoul Vallon and Bernardo José da Silva Estácio and Rafael Prikladnicki and Thomas Grechenig",
keywords = "Global software development",
keywords = "Global software engineering",
keywords = "Distributed software development",
keywords = "Agile software development",
keywords = "Agile practices",
keywords = "Scrum",
keywords = "Extreme programming",
keywords = "XP",
keywords = "Systematic literature review ",
abstract = "AbstractContext Developing software in distributed development environments exhibits coordination, control and communication challenges. Agile practices, which demand frequent communication and self-organization between remote sites, are increasingly found in global software development (GSD) to mitigate said challenges. Objective We aim to provide detailed insight into what is reported on the successful application of agile practices in \{GSD\} from 1999 to 2016 and also identify the most frequently applied agile practices and reported distribution scenarios. We further strive to uncover research opportunities and gaps in the field of agile GSD. Method We build our systematic literature review on top of a previous review, which investigated studies published between 1999 and 2009, and extend the review by years 2010–2016, for which we conduct both a quantitative and a qualitative analysis. Results Our results show that the majority of the cases studied is global and involves complex distribution scenarios with Scrum or combined Scrum/Extreme Programming being the most used agile methods. Key results include that in contrast to 1999–2009, where four Extreme Programming practices were among the ten most frequently used agile practices, in 2010–2016 Scrum is in the center of agile \{GSD\} implementations with eight Scrum-based practices in the top ten agile practices used in GSD. Conclusion Agile \{GSD\} is a maturing research field with higher quality contributions and a greater variety of publication types and methods from 2010 to 2016 than before from 1999 to 2009. However, researchers need to report full empirical contextual details of their studied cases in order to improve the generalizability of results and allow the future creation of stronger frameworks to drive the implementation of agile practices in GSD. "
}
@article{AlZubidy201772,
title = "Vision for \{SLR\} tooling infrastructure: Prioritizing value-added requirements ",
journal = "Information and Software Technology ",
volume = "91",
number = "",
pages = "72 - 81",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.06.007",
url = "https://www.sciencedirect.com/science/article/pii/S0950584916304645",
author = "Ahmed Al-Zubidy and Jeffrey C. Carver and David P. Hale and Edgar E. Hassler",
keywords = "Systematic literature review",
keywords = "Empirical software engineering",
keywords = "Tooling infrastructure ",
abstract = "AbstractContext Even with the increasing use of Systematic Literature Reviews (SLR) in software engineering (SE), there are still a number of barriers faced by \{SLR\} authors. These barriers increase the cost of conducting SLRs. Objective For many of these barriers, appropriate tool support could reduce their impact. In this paper, we use interactions with the \{SLR\} community in \{SE\} to identify and prioritize a set of requirements for \{SLR\} tooling infrastructure. Method This paper analyzes and combines the results from three studies on \{SLR\} process barriers and \{SLR\} tool requirements to produce a prioritized list of functional requirements for \{SLR\} tool support. Using this list of requirements, we perform a feature analysis of the current \{SLR\} support tools to identify requirements that are supported as well as identify the need for additional tooling infrastructure. Results The analysis resulted in a list 112 detailed requirements (consolidated into a set of composite requirements) that \{SE\} community desires in \{SLR\} support tools. The requirements span all the phases of the \{SLR\} process. The results show that, while recent tools cover more of the requirements, there are a number of high-priority requirements that are not yet fully covered by any of the existing tools. Conclusion The existing set of \{SLR\} tools do not cover all the requirements posed by the community. The list of requirements in this paper is useful for tool developers and researchers wishing to provide support to the \{SLR\} community with SE. "
}
@article{Olorisade20171,
title = "Reproducibility of studies on text mining for citation screening in systematic reviews: Evaluation and checklist ",
journal = "Journal of Biomedical Informatics ",
volume = "73",
number = "",
pages = "1 - 13",
year = "2017",
note = "",
issn = "1532-0464",
doi = "https://doi.org/10.1016/j.jbi.2017.07.010",
url = "https://www.sciencedirect.com/science/article/pii/S1532046417301661",
author = "Babatunde Kazeem Olorisade and Pearl Brereton and Peter Andras",
keywords = "Citation screening",
keywords = "Systematic review",
keywords = "Reproducibility",
keywords = "Text mining",
keywords = "Reproducible research ",
abstract = "AbstractContext Independent validation of published scientific results through study replication is a pre-condition for accepting the validity of such results. In computation research, full replication is often unrealistic for independent results validation, therefore, study reproduction has been justified as the minimum acceptable standard to evaluate the validity of scientific claims. The application of text mining techniques to citation screening in the context of systematic literature reviews is a relatively young and growing computational field with high relevance for software engineering, medical research and other fields. However, there is little work so far on reproduction studies in the field. Objective In this paper, we investigate the reproducibility of studies in this area based on information contained in published articles and we propose reporting guidelines that could improve reproducibility. Methods The study was approached in two ways. Initially we attempted to reproduce results from six studies, which were based on the same raw dataset. Then, based on this experience, we identified steps considered essential to successful reproduction of text mining experiments and characterized them to measure how reproducible is a study given the information provided on these steps. 33 articles were systematically assessed for reproducibility using this approach. Results Our work revealed that it is currently difficult if not impossible to independently reproduce the results published in any of the studies investigated. The lack of information about the datasets used limits reproducibility of about 80% of the studies assessed. Also, information about the machine learning algorithms is inadequate in about 27% of the papers. On the plus side, the third party software tools used are mostly free and available. Conclusions The reproducibility potential of most of the studies can be significantly improved if more attention is paid to information provided on the datasets used, how they were partitioned and utilized, and how any randomization was controlled. We introduce a checklist of information that needs to be provided in order to ensure that a published study can be reproduced. "
}
@article{Hannay20091110,
title = "The effectiveness of pair programming: A meta-analysis ",
journal = "Information and Software Technology ",
volume = "51",
number = "7",
pages = "1110 - 1122",
year = "2009",
note = "Special Section: Software Engineering for Secure SystemsSoftware Engineering for Secure Systems ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2009.02.001",
url = "https://www.sciencedirect.com/science/article/pii/S0950584909000123",
author = "Jo E. Hannay and Tore Dybå and Erik Arisholm and Dag I.K. Sjøberg",
keywords = "Pair programming",
keywords = "Evidence-based software engineering",
keywords = "Systematic review",
keywords = "Meta-analysis",
keywords = "Fixed effects",
keywords = "Random effects ",
abstract = "Several experiments on the effects of pair versus solo programming have been reported in the literature. We present a meta-analysis of these studies. The analysis shows a small significant positive overall effect of pair programming on quality, a medium significant positive overall effect on duration, and a medium significant negative overall effect on effort. However, between-study variance is significant, and there are signs of publication bias among published studies on pair programming. A more detailed examination of the evidence suggests that pair programming is faster than solo programming when programming task complexity is low and yields code solutions of higher quality when task complexity is high. The higher quality for complex tasks comes at a price of considerably greater effort, while the reduced completion time for the simpler tasks comes at a price of noticeably lower quality. We conclude that greater attention should be given to moderating factors on the effects of pair programming. "
}
@article{Ali201465,
title = "A systematic literature review on the industrial use of software process simulation ",
journal = "Journal of Systems and Software ",
volume = "97",
number = "",
pages = "65 - 85",
year = "2014",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2014.06.059",
url = "https://www.sciencedirect.com/science/article/pii/S0164121214001502",
author = "Nauman Bin Ali and Kai Petersen and Claes Wohlin",
keywords = "Software process simulation",
keywords = "Systematic literature review",
keywords = "Evidence based software engineering ",
abstract = "AbstractContext Software process simulation modelling (SPSM) captures the dynamic behaviour and uncertainty in the software process. Existing literature has conflicting claims about its practical usefulness: \{SPSM\} is useful and has an industrial impact; \{SPSM\} is useful and has no industrial impact yet; \{SPSM\} is not useful and has little potential for industry. Objective To assess the conflicting standpoints on the usefulness of SPSM. Method A systematic literature review was performed to identify, assess and aggregate empirical evidence on the usefulness of SPSM. Results In the primary studies, to date, the persistent trend is that of proof-of-concept applications of software process simulation for various purposes (e.g. estimation, training, process improvement, etc.). They score poorly on the stated quality criteria. Also only a few studies report some initial evaluation of the simulation models for the intended purposes. Conclusion There is a lack of conclusive evidence to substantiate the claimed usefulness of \{SPSM\} for any of the intended purposes. A few studies that report the cost of applying simulation do not support the claim that it is an inexpensive method. Furthermore, there is a paramount need for improvement in conducting and reporting simulation studies with an emphasis on evaluation against the intended purpose. "
}
@article{Schneider2013119,
title = "Solutions in global software engineering: A systematic literature review ",
journal = "International Journal of Information Management ",
volume = "33",
number = "1",
pages = "119 - 132",
year = "2013",
note = "",
issn = "0268-4012",
doi = "https://doi.org/10.1016/j.ijinfomgt.2012.06.002",
url = "https://www.sciencedirect.com/science/article/pii/S0268401212000989",
author = "Stefan Schneider and Richard Torkar and Tony Gorschek",
keywords = "Systematic literature review",
keywords = "Global software engineering",
keywords = "Solution",
keywords = "Process model",
keywords = "Distributed development",
keywords = "Solutions ",
abstract = "Global software engineering (GSE) has received increased attention, as globalization enables and encourages increased distribution of product development. Many empirical studies and systematic literature reviews (SLRs) focus on the identification of challenges, this paper however presents the first \{SLR\} collecting and analyzing solutions associated with GSE, while also evaluating the level of empirical validation of said solutions. As a starting point the paper presents a \{GSE\} model, designed to categorize solutions into process areas, useful for the analysis of the research community's contributions to state-of-the-art and identifying fundamental gaps in research. In addition, the model categorizing the solutions is populated with references and good-examples, useful for practitioners, which can use the model to find solutions to overall challenges in various process areas. The overall results of the systematic review revealed more than 330 papers containing 127 solutions that were then identified and mapped to the model. The process areas of project management are highly populated, while other areas like product integration have received surprisingly little attention. In addition, selected process area is elaborated upon in terms of contents and deficiencies. "
}
@article{SánchezGuinea2016251,
title = "A systematic review on the engineering of software for ubiquitous systems ",
journal = "Journal of Systems and Software ",
volume = "118",
number = "",
pages = "251 - 276",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.05.024",
url = "https://www.sciencedirect.com/science/article/pii/S0164121216300553",
author = "Alejandro Sánchez Guinea and Grégory Nain and Yves Le Traon",
keywords = "Empirical software engineering",
keywords = "Evidence-based software engineering",
keywords = "Systematic review",
keywords = "Research synthesis",
keywords = "Software development cycle",
keywords = "Ubiquitous systems",
keywords = "Development methods",
keywords = "Pervasive systems ",
abstract = "Abstract Context: Software engineering for ubiquitous systems has experienced an important and rapid growth, however the vast research corpus makes it difficult to obtain valuable information from it. Objective: To identify, evaluate, and synthesize research about the most relevant approaches addressing the different phases of the software development life cycle for ubiquitous systems. Method: We conducted a systematic literature review of papers presenting and evaluating approaches for the different phases of the software development life cycle for ubiquitous systems. Approaches were classified according to the phase of the development cycle they addressed, identifying their main concerns and limitations. Results: We identified 128 papers reporting 132 approaches addressing issues related to different phases of the software development cycle for ubiquitous systems. Most approaches have been aimed at addressing the implementation, evolution/maintenance, and feedback phases, while others phases such as testing need more attention from researchers. Conclusion: We recommend to follow existing guidelines when conducting case studies to make the studies more reproducible and closer to real life cases. While some phases of the development cycle have been extensively explored, there is still room for research in other phases, toward a more agile and integrated cycle, from requirements to testing and feedback. "
}
@article{Garousi2016106,
title = "Challenges and best practices in industry-academia collaborations in software engineering: A systematic literature review ",
journal = "Information and Software Technology ",
volume = "79",
number = "",
pages = "106 - 127",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2016.07.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584916301203",
author = "Vahid Garousi and Kai Petersen and Baris Ozkan",
keywords = "Software engineering",
keywords = "Industry-academia collaborations",
keywords = "Industry",
keywords = "Universities",
keywords = "Challenges",
keywords = "Success patterns",
keywords = "Best practices",
keywords = "Systematic literature review ",
abstract = "Abstract Context: The global software industry and the software engineering (SE) academia are two large communities. However, unfortunately, the level of joint industry-academia collaborations in \{SE\} is still relatively very low, compared to the amount of activity in each of the two communities. It seems that the two ’camps’ show only limited interest/motivation to collaborate with one other. Many researchers and practitioners have written about the challenges, success patterns (what to do, i.e., how to collaborate) and anti-patterns (what not do do) for industry-academia collaborations. Objective: To identify (a) the challenges to avoid risks to the collaboration by being aware of the challenges, (b) the best practices to provide an inventory of practices (patterns) allowing for an informed choice of practices to use when planning and conducting collaborative projects. Method: A systematic review has been conducted. Synthesis has been done using grounded-theory based coding procedures. Results: Through thematic analysis we identified 10 challenge themes and 17 best practice themes. A key outcome was the inventory of best practices, the most common ones recommended in different contexts were to hold regular workshops and seminars with industry, assure continuous learning from industry and academic sides, ensure management engagement, the need for a champion, basing research on real-world problems, showing explicit benefits to the industry partner, be agile during the collaboration, and the co-location of the researcher on the industry side. Conclusion: Given the importance of industry-academia collaboration to conduct research of high practical relevance we provide a synthesis of challenges and best practices, which can be used by researchers and practitioners to make informed decisions on how to structure their collaborations. "
}
@article{Zahedi2016995,
title = "A systematic review of knowledge sharing challenges and practices in global software development ",
journal = "International Journal of Information Management ",
volume = "36",
number = "6, Part A",
pages = "995 - 1019",
year = "2016",
note = "",
issn = "0268-4012",
doi = "https://doi.org/10.1016/j.ijinfomgt.2016.06.007",
url = "https://www.sciencedirect.com/science/article/pii/S026840121630384X",
author = "Mansooreh Zahedi and Mojtaba Shahin and Muhammad Ali Babar",
keywords = "Knowledge sharing",
keywords = "Knowledge management (KM)",
keywords = "Global software development (GSD)",
keywords = "Systematic literature review (SLR)",
keywords = "Empirical software engineering ",
abstract = "AbstractContext Global Software Development (GSD) presents significant challenges to share and understand knowledge required for developing software. Organizations are expected to implement appropriate practices to address knowledge-sharing challenges in GSD. With the growing literature on \{GSD\} and its widespread adoption, it is important to build a body of knowledge to support future research and effective knowledge sharing practices. Objective We aimed at systematically identifying and synthesizing knowledge sharing challenges and practices. We also intended to classify the recurrent challenges and most frequently reported practices in different contextual settings. Method We used Systematic Literature Review (SLR) for reviewing 61 primary studies that were selected after searching the \{GSD\} literature published over the last 14 years (2000–September 2014). We applied thematic analysis method for analysing the data extracted from the reviewed primary studies. Results Our findings revealed that knowledge sharing challenges and practices in \{GSD\} could be classified in 6 main themes: management, team structure, work processes/practices, team cognition, social attributes and technology. In regard to contextual settings, we found empirical studies were mainly conducted in an offshore outsourcing collaboration model distributed between two sites. Most of the studied organizations were large enterprises. Many of the studies did not report any information for several contextual attributes that made it difficult to analyse the reported challenges and practices with respect to their respective contexts. Conclusion We can conclude: (a) there is a higher tendency among researchers to report practices than challenges of knowledge sharing in GSD. (b) Given our analysis, most of the reported knowledge sharing challenges and practices fall under the theme of “work practices”. (c) The technology related knowledge-sharing challenges are the least reported; we discussed the available technologies for supporting knowledge sharing needs in GSD. (d) The organizational contextual information is missing from a large number of studies; hence, it was not possible to investigate the potential relations between knowledge sharing challenges/practices and the contextual attributes of \{GSD\} teams. We assert the need of exploring knowledge sharing in the context of small/medium sized organizations to avoid the risk of findings being biased by specific empirical setting (e.g., large enterprises distributed between \{US\} and India). "
}
@article{deMagalhães201576,
title = "Investigations about replication of empirical studies in software engineering: A systematic mapping study ",
journal = "Information and Software Technology ",
volume = "64",
number = "",
pages = "76 - 101",
year = "2015",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.02.001",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915000300",
author = "Cleyton V.C. de Magalhães and Fabio Q.B. da Silva and Ronnie E.S. Santos and Marcos Suassuna",
keywords = "Replications",
keywords = "Experiments",
keywords = "Empirical studies",
keywords = "Mapping study",
keywords = "Systematic literature review",
keywords = "Software engineering ",
abstract = "AbstractContext Two recent mapping studies which were intended to verify the current state of replication of empirical studies in Software Engineering (SE) identified two sets of studies: empirical studies actually reporting replications (published between 1994 and 2012) and a second group of studies that are concerned with definitions, classifications, processes, guidelines, and other research topics or themes about replication work in empirical software engineering research (published between 1996 and 2012). Objective In this current article, our goal is to analyze and discuss the contents of the second set of studies about replications to increase our understanding of the current state of the work on replication in empirical software engineering research. Method We applied the systematic literature review method to build a systematic mapping study, in which the primary studies were collected by two previous mapping studies covering the period 1996–2012 complemented by manual and automatic search procedures that collected articles published in 2013. Results We analyzed 37 papers reporting studies about replication published in the last 17 years. These papers explore different topics related to concepts and classifications, presented guidelines, and discuss theoretical issues that are relevant for our understanding of replication in our field. We also investigated how these 37 papers have been cited in the 135 replication papers published between 1994 and 2012. Conclusions Replication in \{SE\} still lacks a set of standardized concepts and terminology, which has a negative impact on the replication work in our field. To improve this situation, it is important that the \{SE\} research community engage on an effort to create and evaluate taxonomy, frameworks, guidelines, and methodologies to fully support the development of replications. "
}
@article{Soomro201652,
title = "The effect of software engineers’ personality traits on team climate and performance: A Systematic Literature Review ",
journal = "Information and Software Technology ",
volume = "73",
number = "",
pages = "52 - 65",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2016.01.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584916000082",
author = "Arjumand Bano Soomro and Norsaremah Salleh and Emilia Mendes and John Grundy and Giles Burch and Azlin Nordin",
keywords = "Software team climate",
keywords = "Personality and software engineering",
keywords = "Systematic literature review",
keywords = "Team performance ",
abstract = "AbstractContext Over the past 50 years numerous studies have investigated the possible effect that software engineers’ personalities may have upon their individual tasks and teamwork. These have led to an improved understanding of that relationship; however, the analysis of personality traits and their impact on the software development process is still an area under investigation and debate. Further, other than personality traits, “team climate” is also another factor that has also been investigated given its relationship with software teams’ performance. Objective The aim of this paper is to investigate how software professionals’ personality is associated with team climate and team performance. Method In this paper we detail a Systematic Literature Review (SLR) of the effect of software engineers’ personality traits and team climate on software team performance. Results Our main findings include 35 primary studies that have addressed the relationship between personality and team performance without considering team climate. The findings showed that team climate comprises a wide range of factors that fall within the fields of management and behavioral sciences. Most of the studies used undergraduate students as subjects and as surrogates of software professionals. Conclusions The findings from this \{SLR\} would be beneficial for understanding the personality assessment of software development team members by revealing the traits of personality taxonomy, along with the measurement of the software development team working environment. These measurements would be useful in examining the success and failure possibilities of software projects in development processes. General terms Human factors, performance. "
}
@article{Hassler2016122,
title = "Identification of \{SLR\} tool needs – results of a community workshop ",
journal = "Information and Software Technology ",
volume = "70",
number = "",
pages = "122 - 129",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.10.011",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915001779",
author = "Edgar Hassler and Jeffrey C. Carver and David Hale and Ahmed Al-Zubidy",
keywords = "Systematic literature review",
keywords = "Community workshops",
keywords = "Research infrastructure",
keywords = "Tool features ",
abstract = "Abstract Context: With the increasing popularity of the Systematic Literature Review (SLR) process, there is also an increasing need for tool support. Objective:The goal of this work was to consult the software engineering researchers who conduct \{SLRs\} to identify and prioritize the necessary \{SLR\} tool features. Method: To gather information required to address this goal, we invited \{SLR\} authors to participate in an interactive 2 h workshop structured around the Nominal Group Technique. Results: The workshop outcomes indicated that Search &amp; Selection and Collaboration are the two highest priority tool features. The results also showed that most of the high-priority features are not well-supported in current tools. Conclusion: These results support and extend the results of prior work. \{SLR\} tool authors can use these findings to guide future development efforts. "
}
@article{Gasparic2016101,
title = "What recommendation systems for software engineering recommend: A systematic literature review ",
journal = "Journal of Systems and Software ",
volume = "113",
number = "",
pages = "101 - 113",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2015.11.036",
url = "https://www.sciencedirect.com/science/article/pii/S0164121215002605",
author = "Marko Gasparic and Andrea Janes",
keywords = "Recommendation system for software engineering",
keywords = "Systematic literature review ",
abstract = "Abstract A recommendation system for software engineering (RSSE) is a software application that provides information items estimated to be valuable for a software engineering task in a given context. Present the results of a systematic literature review to reveal the typical functionality offered by existing RSSEs, research gaps, and possible research directions. We evaluated 46 papers studying the benefits, the data requirements, the information and recommendation types, and the effort requirements of \{RSSE\} systems. We include papers describing tools that support source code related development published between 2003 and 2013. The results show that \{RSSEs\} typically visualize source code artifacts. They aim to improve system quality, make the development process more efficient and less expensive, lower developer’s cognitive load, and help developers to make better decisions. They mainly support reuse actions and debugging, implementation, and maintenance phases. The majority of the systems are reactive. Unexploited opportunities lie in the development of recommender systems outside the source code domain. Furthermore, current \{RSSE\} systems use very limited context information and rely on simple models. Context-adapted and proactive behavior could improve the acceptance of \{RSSE\} systems in practice. "
}
@article{Lane2011424,
title = "Process models for service-based applications: A systematic literature review ",
journal = "Information and Software Technology ",
volume = "53",
number = "5",
pages = "424 - 439",
year = "2011",
note = "Special Section on Best Papers from \{XP2010\} ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2010.12.005",
url = "https://www.sciencedirect.com/science/article/pii/S0950584910002211",
author = "Stephen Lane and Ita Richardson",
keywords = "SOA",
keywords = "Service-based application",
keywords = "Software process",
keywords = "Systematic literature review ",
abstract = "Context Service-Oriented Computing (SOC) is a promising computing paradigm which facilitates the development of adaptive and loosely coupled service-based applications (SBAs). Many of the technical challenges pertaining to the development of \{SBAs\} have been addressed, however, there are still outstanding questions relating to the processes required to develop them. Objective The objective of this study is to systematically identify process models for developing service-based applications (SBAs) and review the processes within them. This will provide a useful starting point for any further research in the area. A secondary objective of the study is to identify process models which facilitate the adaptation of SBAs. Method In order to achieve this objective a systematic literature review (SLR) of the existing software engineering literature is conducted. Results During this research 722 studies were identified using a predefined search strategy, this number was narrowed down to 57 studies based on a set of strict inclusion and exclusion criteria. The results are reported both quantitatively in the form of a mapping study, as well as qualitatively in the form of a narrative summary of the key processes identified. Conclusion There are many process models reported for the development of \{SBAs\} varying in detail and maturity, this review has identified and categorised the processes within those process models. The review has also identified and evaluated process models which facilitate the adaptation of SBAs. "
}
@article{Kosar201677,
title = "Domain-Specific Languages: A Systematic Mapping Study ",
journal = "Information and Software Technology ",
volume = "71",
number = "",
pages = "77 - 91",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.11.001",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915001858",
author = "Tomaž Kosar and Sudev Bohra and Marjan Mernik",
keywords = "Domain-Specific Languages",
keywords = "Systematic Mapping Study",
keywords = "Systematic Review ",
abstract = "Abstract Context: In this study we report on a Systematic Mapping Study (SMS) for Domain-Specific Languages (DSLs), based on an automatic search including primary studies from journals, conferences, and workshops during the period from 2006 until 2012. Objective: The main objective of the described work was to perform an \{SMS\} on \{DSLs\} to better understand the \{DSL\} research field, identify research trends, and any possible open issues. The set of research questions was inspired by a \{DSL\} survey paper published in 2005. Method: We conducted a \{SMS\} over 5 stages: defining research questions, conducting the search, screening, classifying, and data extraction. Our \{SMS\} included 1153 candidate primary studies from the \{ISI\} Web of Science and \{ACM\} Digital Library, 390 primary studies were classified after screening. Results: This \{SMS\} discusses two main research questions: research space and trends/demographics of the literature within the field of DSLs. Both research questions are further subdivided into several research sub-questions. The results from the first research question clearly show that the \{DSL\} community focuses more on the development of new techniques/methods rather than investigating the integrations of \{DSLs\} with other software engineering processes or measuring the effectiveness of \{DSL\} approaches. Furthermore, there is a clear lack of evaluation research. Amongst different \{DSL\} development phases more attention is needed in regard to domain analysis, validation, and maintenance. The second research question revealed that the number of publications remains stable, and has not increased over the years. Top cited papers and venues are mentioned, as well as identifying the more active institutions carrying \{DSL\} research. Conclusion: The statistical findings regarding research questions paint an interesting picture about the mainstreams of the \{DSL\} community, as well as open issues where researchers can improve their research in their future work. "
}
@article{Nguyen201562,
title = "An extensive systematic review on the Model-Driven Development of secure systems ",
journal = "Information and Software Technology ",
volume = "68",
number = "",
pages = "62 - 81",
year = "2015",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.08.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915001482",
author = "Phu H. Nguyen and Max Kramer and Jacques Klein and Yves Le Traon",
keywords = "Systematic review",
keywords = "Model-Driven Security",
keywords = "MDS",
keywords = "Model-Driven Engineering",
keywords = "MDE",
keywords = "Software security engineering ",
abstract = "Abstract Context: Model-Driven Security (MDS) is as a specialised Model-Driven Engineering research area for supporting the development of secure systems. Over a decade of research on \{MDS\} has resulted in a large number of publications. Objective: To provide a detailed analysis of the state of the art in MDS, a systematic literature review (SLR ) is essential. Method: We conducted an extensive \{SLR\} on MDS. Derived from our research questions, we designed a rigorous, extensive search and selection process to identify a set of primary \{MDS\} studies that is as complete as possible. Our three-pronged search process consists of automatic searching, manual searching, and snowballing. After discovering and considering more than thousand relevant papers, we identified, strictly selected, and reviewed 108 \{MDS\} publications. Results: The results of our \{SLR\} show the overall status of the key artefacts of MDS, and the identified primary \{MDS\} studies. For example, regarding security modelling artefact, we found that developing domain-specific languages plays a key role in many \{MDS\} approaches. The current limitations in each \{MDS\} artefact are pointed out and corresponding potential research directions are suggested. Moreover, we categorise the identified primary \{MDS\} studies into 5 significant \{MDS\} studies, and other emerging or less common \{MDS\} studies. Finally, some trend analyses of \{MDS\} research are given. Conclusion: Our results suggest the need for addressing multiple security concerns more systematically and simultaneously, for tool chains supporting the \{MDS\} development cycle, and for more empirical studies on the application of \{MDS\} methodologies. To the best of our knowledge, this \{SLR\} is the first in the field of Software Engineering that combines a snowballing strategy with database searching. This combination has delivered an extensive literature study on MDS. "
}
@article{Bano2015148,
title = "A systematic review on the relationship between user involvement and system success ",
journal = "Information and Software Technology ",
volume = "58",
number = "",
pages = "148 - 169",
year = "2015",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.06.011",
url = "https://www.sciencedirect.com/science/article/pii/S0950584914001505",
author = "Muneera Bano and Didar Zowghi",
keywords = "User involvement",
keywords = "Software development",
keywords = "Systematic Literature Review ",
abstract = "AbstractContext For more than four decades it has been intuitively accepted that user involvement (UI) during system development lifecycle leads to system success. However when the researchers have evaluated the user involvement and system success (UI-SS) relationship empirically, the results were not always positive. Objective Our objective was to explore the UI-SS relationship by synthesizing the results of all the studies that have empirically investigated this complex phenomenon. Method We performed a Systematic Literature Review (SLR) following the steps provided in the guidelines of Evidence Based Software Engineering. From the resulting studies we extracted data to answer our 9 research questions related to the UI-SS relationship, identification of users, perspectives of UI, benefits, problems and challenges of UI, degree and level of UI, relevance of stages of software development lifecycle (SDLC) and the research method employed on the UI-SS relationship. Results Our systematic review resulted in selecting 87 empirical studies published during the period 1980–2012. Among 87 studies reviewed, 52 reported that \{UI\} positively contributes to system success, 12 suggested a negative contribution and 23 were uncertain. The UI-SS relationship is neither direct nor binary, and there are various confounding factors that play their role. The identification of users, their degree/level of involvement, stage of \{SDLC\} for UI, and choice of research method have been claimed to have impact on the UI-SS relationship. However, there is not sufficient empirical evidence available to support these claims. Conclusion Our results have revealed that \{UI\} does contribute positively to system success. But it is a double edged sword and if not managed carefully it may cause more problems than benefits. Based on the analysis of 87 studies, we were able to identify factors for effective management of \{UI\} alluding to the causes for inconsistency in the results of published literature. "
}
@article{Cruz201594,
title = "Forty years of research on personality in software engineering: A mapping study ",
journal = "Computers in Human Behavior ",
volume = "46",
number = "",
pages = "94 - 113",
year = "2015",
note = "",
issn = "0747-5632",
doi = "https://doi.org/10.1016/j.chb.2014.12.008",
url = "https://www.sciencedirect.com/science/article/pii/S0747563214007237",
author = "Shirley Cruz and Fabio Q.B. da Silva and Luiz Fernando Capretz",
keywords = "Human factors in software engineering",
keywords = "Software psychology",
keywords = "Empirical software engineering",
keywords = "Mapping study",
keywords = "Systematic literature review ",
abstract = "Abstract In this article, we present a systematic mapping study of research on personality in software engineering. The goal is to plot the landscape of current published empirical and theoretical studies that deal with the role of personality in software engineering. We applied the systematic review method to search and select published articles, and to extract and synthesize data from the selected articles that reported studies about personality. Our search retrieved more than 19,000 articles, from which we selected 90 articles published between 1970 and 2010. Nearly 72% of the studies were published after 2002 and 83% of the studies reported empirical research findings. Data extracted from the 90 studies showed that education and pair programming were the most recurring research topics, and that \{MBTI\} was the most used test. Research related to pair programming, education, team effectiveness, software process allocation, software engineer personality characteristics, and individual performance concentrated over 88% of the studies, while team process, behavior and preferences, and leadership performance were the topics with the smallest number of studies. We conclude that the number of articles has grown in the last few years, but contradictory evidence was found that might have been caused by differences in context, research method, and versions of the tests used in the studies. While this raises a warning for practitioners that wish to use personality tests in practice, it shows several opportunities for the research community to improve and extend findings in this field. "
}
@article{Kitchenham20132049,
title = "A systematic review of systematic review process research in software engineering ",
journal = "Information and Software Technology ",
volume = "55",
number = "12",
pages = "2049 - 2075",
year = "2013",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2013.07.010",
url = "https://www.sciencedirect.com/science/article/pii/S0950584913001560",
author = "Barbara Kitchenham and Pearl Brereton",
keywords = "Systematic review",
keywords = "Systematic literature review",
keywords = "Systematic review methodology",
keywords = "Mapping study ",
abstract = "AbstractContext Many researchers adopting systematic reviews (SRs) have also published papers discussing problems with the \{SR\} methodology and suggestions for improving it. Since guidelines for \{SRs\} in software engineering (SE) were last updated in 2007, we believe it is time to investigate whether the guidelines need to be amended in the light of recent research. Objective To identify, evaluate and synthesize research published by software engineering researchers concerning their experiences of performing \{SRs\} and their proposals for improving the \{SR\} process. Method We undertook a systematic review of papers reporting experiences of undertaking \{SRs\} and/or discussing techniques that could be used to improve the \{SR\} process. Studies were classified with respect to the stage in the \{SR\} process they addressed, whether they related to education or problems faced by novices and whether they proposed the use of textual analysis tools. Results We identified 68 papers reporting 63 unique studies published in \{SE\} conferences and journals between 2005 and mid-2012. The most common criticisms of \{SRs\} were that they take a long time, that \{SE\} digital libraries are not appropriate for broad literature searches and that assessing the quality of empirical studies of different types is difficult. Conclusion We recommend removing advice to use structured questions to construct search strings and including advice to use a quasi-gold standard based on a limited manual search to assist the construction of search stings and evaluation of the search process. Textual analysis tools are likely to be useful for inclusion/exclusion decisions and search string construction but require more stringent evaluation. \{SE\} researchers would benefit from tools to manage the \{SR\} process but existing tools need independent validation. Quality assessment of studies using a variety of empirical methods remains a major problem. "
}
@article{Kupiainen2015143,
title = "Using metrics in Agile and Lean Software Development – A systematic literature review of industrial studies ",
journal = "Information and Software Technology ",
volume = "62",
number = "",
pages = "143 - 163",
year = "2015",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.02.005",
url = "https://www.sciencedirect.com/science/article/pii/S095058491500035X",
author = "Eetu Kupiainen and Mika V. Mäntylä and Juha Itkonen",
keywords = "Agile",
keywords = "Lean",
keywords = "Metrics",
keywords = "Measurement",
keywords = "Systematic literature review",
keywords = "Software engineering ",
abstract = "AbstractContext Software industry has widely adopted Agile software development methods. Agile literature proposes a few key metrics but little is known of the actual metrics use in Agile teams. Objective The objective of this paper is to increase knowledge of the reasons for and effects of using metrics in industrial Agile development. We focus on the metrics that Agile teams use, rather than the ones used from outside by software engineering researchers. In addition, we analyse the influence of the used metrics. Method This paper presents a systematic literature review (SLR) on using metrics in industrial Agile software development. We identified 774 papers, which we reduced to 30 primary studies through our paper selection process. Results The results indicate that the reasons for and the effects of using metrics are focused on the following areas: sprint planning, progress tracking, software quality measurement, fixing software process problems, and motivating people. Additionally, we show that although Agile teams use many metrics suggested in the Agile literature, they also use many custom metrics. Finally, the most influential metrics in the primary studies are Velocity and Effort estimate. Conclusion The use of metrics in Agile software development is similar to Traditional software development. Projects and sprints need to be planned and tracked. Quality needs to be measured. Problems in the process need to be identified and fixed. Future work should focus on metrics that had high importance but low prevalence in our study, as they can offer the largest impact to the software industry. "
}
@article{Idri2015206,
title = "Analogy-based software development effort estimation: A systematic mapping and review ",
journal = "Information and Software Technology ",
volume = "58",
number = "",
pages = "206 - 230",
year = "2015",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.07.013",
url = "https://www.sciencedirect.com/science/article/pii/S0950584914001815",
author = "Ali Idri and Fatima azzahra Amazal and Alain Abran",
keywords = "Mapping study",
keywords = "Systematic literature review",
keywords = "Software development effort estimation",
keywords = "Analogy",
keywords = "Case-based reasoning ",
abstract = "AbstractContext Analogy-based Software development Effort Estimation (ASEE) techniques have gained considerable attention from the software engineering community. However, existing systematic map and review studies on software development effort prediction have not investigated in depth several issues of \{ASEE\} techniques, to the exception of comparisons with other types of estimation techniques. Objective The objective of this research is twofold: (1) to classify \{ASEE\} studies which primary goal is to propose new or modified \{ASEE\} techniques according to five criteria: research approach, contribution type, techniques used in combination with \{ASEE\} methods, and \{ASEE\} steps, as well as identifying publication channels and trends and (2) to analyze these studies from five perspectives: estimation accuracy, accuracy comparison, estimation context, impact of the techniques used in combination with \{ASEE\} methods, and \{ASEE\} tools. Method We performed a systematic mapping of studies for which the primary goal is to develop or to improve \{ASEE\} techniques published in the period 1990–2012, and reviewed them based on an automated search of four electronic databases. Results In total, we identified 65 studies published between 1990 and 2012, and classified them based on our predefined classification criteria. The mapping study revealed that most researchers focus on addressing problems related to the first step of an \{ASEE\} process, that is, feature and case subset selection. The results of our detailed analysis show that \{ASEE\} methods outperform the eight techniques with which they were compared, and tend to yield acceptable results especially when combining \{ASEE\} techniques with Fuzzy Logic (FL) or Genetic Algorithms (GA). Conclusion Based on the findings of this study, the use of other techniques such \{FL\} and \{GA\} in combination with an \{ASEE\} method is promising to generate more accurate estimates. However, the use of \{ASEE\} techniques by practitioners is still limited: developing more \{ASEE\} tools may facilitate the application of these techniques and then lead to increasing the use of \{ASEE\} techniques in industry. "
}
@article{Kanewala20141219,
title = "Testing scientific software: A systematic literature review ",
journal = "Information and Software Technology ",
volume = "56",
number = "10",
pages = "1219 - 1232",
year = "2014",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.05.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584914001232",
author = "Upulee Kanewala and James M. Bieman",
keywords = "Scientific software",
keywords = "Software testing",
keywords = "Systematic literature review",
keywords = "Software quality ",
abstract = "AbstractContext Scientific software plays an important role in critical decision making, for example making weather predictions based on climate models, and computation of evidence for research publications. Recently, scientists have had to retract publications due to errors caused by software faults. Systematic testing can identify such faults in code. Objective This study aims to identify specific challenges, proposed solutions, and unsolved problems faced when testing scientific software. Method We conducted a systematic literature survey to identify and analyze relevant literature. We identified 62 studies that provided relevant information about testing scientific software. Results We found that challenges faced when testing scientific software fall into two main categories: (1) testing challenges that occur due to characteristics of scientific software such as oracle problems and (2) testing challenges that occur due to cultural differences between scientists and the software engineering community such as viewing the code and the model that it implements as inseparable entities. In addition, we identified methods to potentially overcome these challenges and their limitations. Finally we describe unsolved challenges and how software engineering researchers and practitioners can help to overcome them. Conclusions Scientific software presents special challenges for testing. Specifically, cultural differences between scientist developers and software engineers, along with the characteristics of the scientific software make testing more difficult. Existing techniques such as code clone detection can help to improve the testing process. Software engineers should consider special challenges posed by scientific software such as oracle problems when developing testing techniques. "
}
@article{Bjørnson20081055,
title = "Knowledge management in software engineering: A systematic review of studied concepts, findings and research methods used ",
journal = "Information and Software Technology ",
volume = "50",
number = "11",
pages = "1055 - 1068",
year = "2008",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2008.03.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584908000487",
author = "Finn Olav Bjørnson and Torgeir Dingsøyr",
keywords = "Software engineering",
keywords = "Knowledge management",
keywords = "Learning software organization",
keywords = "Software process improvement",
keywords = "Systematic review ",
abstract = "Software engineering is knowledge-intensive work, and how to manage software engineering knowledge has received much attention. This systematic review identifies empirical studies of knowledge management initiatives in software engineering, and discusses the concepts studied, the major findings, and the research methods used. Seven hundred and sixty-two articles were identified, of which 68 were studies in an industry context. Of these, 29 were empirical studies and 39 reports of lessons learned. More than half of the empirical studies were case studies. The majority of empirical studies relate to technocratic and behavioural aspects of knowledge management, while there are few studies relating to economic, spatial and cartographic approaches. A finding reported across multiple papers was the need to not focus exclusively on explicit knowledge, but also consider tacit knowledge. We also describe implications for research and for practice. "
}
@article{Ding2014545,
title = "Knowledge-based approaches in software documentation: A systematic literature review ",
journal = "Information and Software Technology ",
volume = "56",
number = "6",
pages = "545 - 567",
year = "2014",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.01.008",
url = "https://www.sciencedirect.com/science/article/pii/S0950584914000196",
author = "Wei Ding and Peng Liang and Antony Tang and Hans van Vliet",
keywords = "Knowledge-based approach",
keywords = "Software documentation",
keywords = "Systematic literature review",
keywords = "Knowledge activity",
keywords = "Software architecture design ",
abstract = "AbstractContext Software documents are core artifacts produced and consumed in documentation activity in the software lifecycle. Meanwhile, knowledge-based approaches have been extensively used in software development for decades, however, the software engineering community lacks a comprehensive understanding on how knowledge-based approaches are used in software documentation, especially documentation of software architecture design. Objective The objective of this work is to explore how knowledge-based approaches are employed in software documentation, their influences to the quality of software documentation, and the costs and benefits of using these approaches. Method We use a systematic literature review method to identify the primary studies on knowledge-based approaches in software documentation, following a pre-defined review protocol. Results Sixty studies are finally selected, in which twelve quality attributes of software documents, four cost categories, and nine benefit categories of using knowledge-based approaches in software documentation are identified. Architecture understanding is the top benefit of using knowledge-based approaches in software documentation. The cost of retrieving information from documents is the major concern when using knowledge-based approaches in software documentation. Conclusions The findings of this review suggest several future research directions that are critical and promising but underexplored in current research and practice: (1) there is a need to use knowledge-based approaches to improve the quality attributes of software documents that receive less attention, especially credibility, conciseness, and unambiguity; (2) using knowledge-based approaches with the knowledge content in software documents which gets less attention in current applications of knowledge-based approaches in software documentation, to further improve the practice of software documentation activity; (3) putting more focus on the application of software documents using the knowledge-based approaches (knowledge reuse, retrieval, reasoning, and sharing) in order to make the most use of software documents; and (4) evaluating the costs and benefits of using knowledge-based approaches in software documentation qualitatively and quantitatively. "
}
@article{González2014821,
title = "Formal verification of static software models in MDE: A systematic review ",
journal = "Information and Software Technology ",
volume = "56",
number = "8",
pages = "821 - 838",
year = "2014",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.03.003",
url = "https://www.sciencedirect.com/science/article/pii/S0950584914000627",
author = "Carlos A. González and Jordi Cabot",
keywords = "MDE",
keywords = "Formal verification",
keywords = "OCL",
keywords = "Systematic literature review ",
abstract = "AbstractContext Model-driven Engineering (MDE) promotes the utilization of models as primary artifacts in all software engineering activities. Therefore, mechanisms to ensure model correctness become crucial, specially when applying \{MDE\} to the development of software, where software is the result of a chain of (semi)automatic model transformations that refine initial abstract models to lower level ones from which the final code is eventually generated. Clearly, in this context, an error in the model/s is propagated to the code endangering the soundness of the resulting software. Formal verification of software models is a promising approach that advocates the employment of formal methods to achieve model correctness, and it has received a considerable amount of attention in the last few years. Objective The objective of this paper is to analyze the state of the art in the field of formal verification of models, restricting the analysis to those approaches applied over static software models complemented or not with constraints expressed in textual languages, typically the Object Constraint Language (OCL). Method We have conducted a Systematic Literature Review (SLR) of the published works in this field, describing their main characteristics. Results The study is based on a set of 48 resources that have been grouped in 18 different approaches according to their affinity. For each of them we have analyzed, among other issues, the formalism used, the support given to OCL, the correctness properties addressed or the feedback yielded by the verification process. Conclusions One of the most important conclusions obtained is that current model verification approaches are strongly influenced by the support given to OCL. Another important finding is that in general, current verification tools present important flaws like the lack of integration into the model designer tool chain or the lack of efficiency when verifying large, real-life models. "
}
@article{Staples20071425,
title = "Experiences using systematic review guidelines ",
journal = "Journal of Systems and Software ",
volume = "80",
number = "9",
pages = "1425 - 1437",
year = "2007",
note = "Evaluation and Assessment in Software EngineeringEASE06 ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2006.09.046",
url = "https://www.sciencedirect.com/science/article/pii/S0164121206002962",
author = "Mark Staples and Mahmood Niazi",
keywords = "Systematic review",
keywords = "Empirical software engineering ",
abstract = "Systematic review is a method to identify, assess and analyse published primary studies to investigate research questions. We critique recently published guidelines for performing systematic reviews on software engineering, and comment on systematic review generally with respect to our experience conducting one. Overall we recommend the guidelines. We recommend researchers clearly and narrowly define research questions to reduce overall effort, and to improve selection and data extraction. We suggest that “complementary” research questions can help clarify the main questions and define selection criteria. We show our project timeline, and discuss possibilities for automating and increasing the acceptance of systematic review. "
}
@article{Cruzes2011440,
title = "Research synthesis in software engineering: A tertiary study ",
journal = "Information and Software Technology ",
volume = "53",
number = "5",
pages = "440 - 455",
year = "2011",
note = "Special Section on Best Papers from \{XP2010\} ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2011.01.004",
url = "https://www.sciencedirect.com/science/article/pii/S095058491100005X",
author = "Daniela S. Cruzes and Tore Dybå",
keywords = "Evidence-based software engineering",
keywords = "Empirical software engineering",
keywords = "Systematic review",
keywords = "Qualitative methods",
keywords = "Mixed-methods ",
abstract = "Context Comparing and contrasting evidence from multiple studies is necessary to build knowledge and reach conclusions about the empirical support for a phenomenon. Therefore, research synthesis is at the center of the scientific enterprise in the software engineering discipline. Objective The objective of this article is to contribute to a better understanding of the challenges in synthesizing software engineering research and their implications for the progress of research and practice. Method A tertiary study of journal articles and full proceedings papers from the inception of evidence-based software engineering was performed to assess the types and methods of research synthesis in systematic reviews in software engineering. Results As many as half of the 49 reviews included in the study did not contain any synthesis. Of the studies that did contain synthesis, two thirds performed a narrative or a thematic synthesis. Only a few studies adequately demonstrated a robust, academic approach to research synthesis. Conclusion We concluded that, despite the focus on systematic reviews, there is limited attention paid to research synthesis in software engineering. This trend needs to change and a repertoire of synthesis methods needs to be an integral part of systematic reviews to increase their significance and utility for research and practice. "
}
@article{Zhang2011625,
title = "Identifying relevant studies in software engineering ",
journal = "Information and Software Technology ",
volume = "53",
number = "6",
pages = "625 - 637",
year = "2011",
note = "Special Section: Best papers from the \{APSECBest\} papers from the \{APSEC\} ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2010.12.010",
url = "https://www.sciencedirect.com/science/article/pii/S0950584910002260",
author = "He Zhang and Muhammad Ali Babar and Paolo Tell",
keywords = "Search strategy",
keywords = "Quasi-gold standard",
keywords = "Systematic literature review",
keywords = "Evidence-based software engineering ",
abstract = "Context Systematic literature review (SLR) has become an important research methodology in software engineering since the introduction of evidence-based software engineering (EBSE) in 2004. One critical step in applying this methodology is to design and execute appropriate and effective search strategy. This is a time-consuming and error-prone step, which needs to be carefully planned and implemented. There is an apparent need for a systematic approach to designing, executing, and evaluating a suitable search strategy for optimally retrieving the target literature from digital libraries. Objective The main objective of the research reported in this paper is to improve the search step of undertaking \{SLRs\} in software engineering (SE) by devising and evaluating systematic and practical approaches to identifying relevant studies in SE. Method We have systematically selected and analytically studied a large number of papers (SLRs) to understand the state-of-the-practice of search strategies in EBSE. Having identified the limitations of the current ad-hoc nature of search strategies used by \{SE\} researchers for SLRs, we have devised a systematic and evidence-based approach to developing and executing optimal search strategies in SLRs. The proposed approach incorporates the concept of ‘quasi-gold standard’ (QGS), which consists of collection of known studies, and corresponding ‘quasi-sensitivity’ into the search process for evaluating search performance. Results We conducted two participant–observer case studies to demonstrate and evaluate the adoption of the proposed QGS-based systematic search approach in support of \{SLRs\} in \{SE\} research. Conclusion We report their findings based on the case studies that the approach is able to improve the rigor of search process in an SLR, as well as it can serve as a supplement to the guidelines for \{SLRs\} in EBSE. We plan to further evaluate the proposed approach using a series of case studies on varying research topics in SE. "
}
@article{Spínola2012759,
title = "Towards a framework to characterize ubiquitous software projects ",
journal = "Information and Software Technology ",
volume = "54",
number = "7",
pages = "759 - 785",
year = "2012",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2012.01.009",
url = "https://www.sciencedirect.com/science/article/pii/S0950584912000304",
author = "Rodrigo Oliveira Spínola and Guilherme Horta Travassos",
keywords = "Ubiquitous computing",
keywords = "Software projects characterization",
keywords = "Systematic review",
keywords = "Experimental software engineering ",
abstract = "Context Ubiquitous Computing (or UbiComp) represents a paradigm in which information processing is thoroughly integrated into everyday objects and activities. From a Software Engineering point of view this development scenario brings new challenges in tailoring or building software processes, impacting current software technologies. However, it has not yet been explicitly shown how to characterize a software project with the perception of ubiquitous computing. Objective This paper presents a conceptual framework to support the characterization of ubiquitous software projects according to their ubiquity adherence level. It also intends to apply such characterization approach to some projects, aiming at observing their adherence with ubiquitous computing principles. Method To follow a research strategy based on systematic reviews and surveys to acquire UbiComp knowledge and organize a conceptual framework regarding ubiquitous computing, which can be used to characterize UbiComp software projects. Besides, to demonstrate its application by characterizing some software projects. Results Ubiquitous computing encapsulates at least 11 different high abstraction level characteristics represented by 123 functional and 45 restrictive factors. Based on this a checklist was organized to allow the characterization of ubiquitous software projects, which has been applied on 26 ubiquitous software projects from four different application domains (ambient intelligence, pervasive healthcare, U-learning, and urban space). No project demonstrated to support more than 65% of the characteristics set. Service omnipresence was observed in all of these projects. However, some characteristics, although identified as necessary in the checklist, were not identified in any of them. Conclusion There are characteristics that identify a software project as ubiquitous. However, a ubiquitous software project does not necessarily have to implement all of them. The application domain can influence the appearing of UbiComp characteristics in software projects, promoting an increase of their adherence to UbiComp and, thus, for additional software technologies to deal with these ubiquitous requirements. "
}
@article{SouzaNeto201684,
title = "Designing service-based applications in the presence of non-functional properties: A mapping study ",
journal = "Information and Software Technology ",
volume = "69",
number = "",
pages = "84 - 105",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.09.004",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915001573",
author = "Plácido A. Souza Neto and Genoveva Vargas-Solar and Umberto Souza da Costa and Martin A. Musicante",
keywords = "Non-functional requirements",
keywords = "Service-based software process",
keywords = "Systematic mapping ",
abstract = "AbstractContext The development of distributed software systems has become an important problem for the software engineering community. Service-based applications are a common solution for this kind of systems. Services provide a uniform mechanism for discovering, integrating and using these resources. In the development of service based applications not only the functionality of services and compositions should be considered, but also conditions in which the system operates. These conditions are called non-functional requirements (NFR). The conformance of applications to \{NFR\} is crucial to deliver software that meets the expectations of its users. Objective This paper presents the results of a systematic mapping carried out to analyze how \{NFR\} have been addressed in the development of service-based applications in the last years, according to different points of view. Method Our analysis applies the systematic mapping approach. It focuses on the analysis of publications organized by categories called facets, which are combined to answer specific research questions. The facets compose a classification schema which is part of the contribution and results. Results This paper presents our findings on how \{NFR\} have been supported in the development of service-based applications by proposing a classification scheme consisting in five facets: (i) programming paradigm (object/service oriented); (ii) contribution (methodology, system, middleware); (iii) software process phase; (iv) technique or mathematical model used for expressing NFR; and (v) the types of \{NFR\} addressed by the papers, based on the classification proposed by the ISO/IEC 9126 specification. The results of our systematic mapping are presented as bubble charts that provide a quantitative analysis to show the frequencies of publications for each facet. The paper also proposes a qualitative analysis based on these plots. This analysis discusses how \{NFR\} (quality properties) have been addressed in the design and development of service-based applications, including methodologies, languages and tools devised to support different phases of the software process. Conclusion This systematic mapping showed that \{NFR\} are not fully considered in all software engineering phases for building service based applications. The study also let us conclude that work has been done for providing models and languages for expressing \{NFR\} and associated middleware for enforcing them at run time. An important finding is that \{NFR\} are not fully considered along all software engineering phases and this opens room for proposing methodologies that fully model NFR. The data collected by our work and used for this systematic mapping are available in https://github.com/placidoneto/systematic-mapping_service-based-app_nfr. "
}
@article{Kroll201830,
title = "Empirical evidence in follow the Sun software development: A systematic mapping study ",
journal = "Information and Software Technology ",
volume = "93",
number = "",
pages = "30 - 44",
year = "2018",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.08.011",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917304639",
author = "Josiane Kroll and Ita Richardson and Rafael Prikladnicki and Jorge L.N. Audy",
keywords = "Global software development",
keywords = "Follow the sun",
keywords = "Time zone management",
keywords = "Virtual teams",
keywords = "Systematic mapping study ",
abstract = "AbstractContext Follow the Sun (FTS) development is a special case of Global Software Development. It is applied in the context of global projects to reduce the software development life-cycle duration. A number of studies have attempted to aggregate a better understanding of \{FTS\} development, but it is still an immature research area. Objective This paper aims to investigate the existing empirical evidence about \{FTS\} research with a focus on identifying what research has been conducted in the area and which results have been obtained. Method To achieve this goal, we performed a systematic mapping study to answer our research questions: “Which \{FTS\} studies have been published in the literature?” and “What empirical support is provided for them?” We investigated papers published between 1990 and 2017. The synthesis was made through classifying the papers into different categories (research topics, research methods, conferences and journals venues for \{FTS\} research, and countries involved in \{FTS\} research). Results We selected 57 papers using a predefined search strategy. The majority of the papers discussing \{FTS\} were published in the International Conference on Global Software Engineering (ICGSE). The main research topic addressed is processes and organization development for FTS. Case studies combined with the interview as a research sub-method is adopted in the most studies performed in FTS. The majority of the existing research and the most active researchers in this topic are from the United States and Brazil. However, India and the United States are the countries that appear most often in the studies conducted to investigate FTS. Conclusion Our findings suggest that \{FTS\} software development is an up-to-date research topic in Software Engineering. However, little information about \{FTS\} has been published over the last few years. The emergent need in this research is the development of evaluation research for testing \{FTS\} feasibility and effectiveness in practice. "
}
@article{Kitchenham2010792,
title = "Systematic literature reviews in software engineering – A tertiary study ",
journal = "Information and Software Technology ",
volume = "52",
number = "8",
pages = "792 - 805",
year = "2010",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2010.03.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584910000467",
author = "Barbara Kitchenham and Rialette Pretorius and David Budgen and O. Pearl Brereton and Mark Turner and Mahmood Niazi and Stephen Linkman",
keywords = "Systematic literature review",
keywords = "Mapping study",
keywords = "Software engineering",
keywords = "Tertiary study ",
abstract = "Context In a previous study, we reported on a systematic literature review (SLR), based on a manual search of 13 journals and conferences undertaken in the period 1st January 2004 to 30th June 2007. Objective The aim of this on-going research is to provide an annotated catalogue of \{SLRs\} available to software engineering researchers and practitioners. This study updates our previous study using a broad automated search. Method We performed a broad automated search to find \{SLRs\} published in the time period 1st January 2004 to 30th June 2008. We contrast the number, quality and source of these \{SLRs\} with \{SLRs\} found in the original study. Results Our broad search found an additional 35 \{SLRs\} corresponding to 33 unique studies. Of these papers, 17 appeared relevant to the undergraduate educational curriculum and 12 appeared of possible interest to practitioners. The number of \{SLRs\} being published is increasing. The quality of papers in conferences and workshops has improved as more researchers use \{SLR\} guidelines. Conclusion \{SLRs\} appear to have gone past the stage of being used solely by innovators but cannot yet be considered a main stream software engineering research methodology. They are addressing a wide range of topics but still have limitations, such as often failing to assess primary study quality. "
}
@article{Turner2010463,
title = "Does the technology acceptance model predict actual use? A systematic literature review ",
journal = "Information and Software Technology ",
volume = "52",
number = "5",
pages = "463 - 479",
year = "2010",
note = "TAIC-PART 2008TAIC-PART 2008 ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2009.11.005",
url = "https://www.sciencedirect.com/science/article/pii/S0950584909002055",
author = "Mark Turner and Barbara Kitchenham and Pearl Brereton and Stuart Charters and David Budgen",
keywords = "Technology acceptance model (TAM)",
keywords = "Systematic literature review",
keywords = "Evidence-based software engineering",
keywords = "Literature review",
keywords = "Actual usage ",
abstract = "Context The technology acceptance model (TAM) was proposed in 1989 as a means of predicting technology usage. However, it is usually validated by using a measure of behavioural intention to use (BI) rather than actual usage. Objective This review examines the evidence that the \{TAM\} predicts actual usage using both subjective and objective measures of actual usage. Method We performed a systematic literature review based on a search of six digital libraries, along with vote-counting meta-analysis to analyse the overall results. Results The search identified 79 relevant empirical studies in 73 articles. The results show that \{BI\} is likely to be correlated with actual usage. However, the \{TAM\} variables perceived ease of use (PEU) and perceived usefulness (PU) are less likely to be correlated with actual usage. Conclusion Care should be taken using the \{TAM\} outside the context in which it has been validated. "
}
@article{Brereton2007571,
title = "Lessons from applying the systematic literature review process within the software engineering domain ",
journal = "Journal of Systems and Software ",
volume = "80",
number = "4",
pages = "571 - 583",
year = "2007",
note = "Software Performance5th International Workshop on Software and Performance ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2006.07.009",
url = "https://www.sciencedirect.com/science/article/pii/S016412120600197X",
author = "Pearl Brereton and Barbara A. Kitchenham and David Budgen and Mark Turner and Mohamed Khalil",
keywords = "Systematic literature review",
keywords = "Empirical software engineering ",
abstract = "A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted. The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights areas where some adaptation of the process to accommodate the domain-specific characteristics of software engineering is needed as well as areas where improvements to current software engineering infrastructure and practices would enhance its applicability. In particular, infrastructure support provided by software engineering indexing databases is inadequate. Also, the quality of abstracts is poor; it is usually not possible to judge the relevance of a study from a review of the abstract alone. "
}
@article{Haghighatkhah201725,
title = "Automotive software engineering: A systematic mapping study ",
journal = "Journal of Systems and Software ",
volume = "128",
number = "",
pages = "25 - 55",
year = "2017",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2017.03.005",
url = "https://www.sciencedirect.com/science/article/pii/S0164121217300560",
author = "Alireza Haghighatkhah and Ahmad Banijamali and Olli-Pekka Pakanen and Markku Oivo and Pasi Kuvaja",
keywords = "Literature survey",
keywords = "Systematic mapping study",
keywords = "Automotive software engineering",
keywords = "Automotive systems",
keywords = "Embedded systems",
keywords = "Software-intensive systems ",
abstract = "Abstract The automotive industry is going through a fundamental change by moving from a mechanical to a software-intensive industry in which most innovation and competition rely on software engineering competence. Over the last few decades, the importance of software engineering in the automotive industry has increased significantly and has attracted much attention from both scholars and practitioners. A large body-of-knowledge on automotive software engineering has accumulated in several scientific publications, yet there is no systematic analysis of that knowledge. This systematic mapping study aims to classify and analyze the literature related to automotive software engineering in order to provide a structured body-of-knowledge, identify well-established topics and potential research gaps. The review includes 679 articles from multiple research sub-area, published between 1990 and 2015. The primary studies were analyzed and classified with respect to five different dimensions. Furthermore, potential research gaps and recommendations for future research are presented. Three areas, namely system/software architecture and design, qualification testing, and reuse were the most frequently addressed topics in the literature. There were fewer comparative and validation studies, and the literature lacks practitioner-oriented guidelines. Overall, research activity on automotive software engineering seems to have high industrial relevance but is relatively lower in its scientific rigor. "
}
@article{deAlmeidaBiolchini2007133,
title = "Scientific research ontology to support systematic review in software engineering ",
journal = "Advanced Engineering Informatics ",
volume = "21",
number = "2",
pages = "133 - 151",
year = "2007",
note = "Ontology of Systems and Software Engineering; Techniques to Support Collaborative Engineering Environments ",
issn = "1474-0346",
doi = "https://doi.org/10.1016/j.aei.2006.11.006",
url = "https://www.sciencedirect.com/science/article/pii/S147403460600070X",
author = "Jorge Calmon de Almeida Biolchini and Paula Gomes Mian and Ana Candida Cruz Natali and Tayana Uchôa Conte and Guilherme Horta Travassos",
keywords = "Experimental software engineering",
keywords = "Systematic review",
keywords = "Experimental study",
keywords = "Ontology",
keywords = "Scientific method ",
abstract = "The term systematic review is used to refer to a specific methodology of research, developed in order to gather and evaluate the available evidence pertaining to a focused topic. It represents a secondary study that depends on primary study results to be accomplished. Several primary studies have been conducted in the field of Software Engineering in the last years, determining an increasing improvement in methodology. However, in most cases software is built with technologies and processes for which developers have insufficient evidence to confirm their suitability, limits, qualities, costs, and inherent risks. Conducting systematic reviews in Software Engineering consists in a major methodological tool to scientifically improve the validity of assertions that can be made in the field and, as a consequence, the reliability degree of the methods that are employed for developing software technologies and supporting software processes. This paper aims at discussing the significance of experimental studies, particularly systematic reviews, and their use in supporting software processes. A template designed to support systematic reviews in Software Engineering is presented, and the development of ontologies to describe knowledge regarding such experimental studies is also introduced. "
}
@article{Walia20091087,
title = "A systematic literature review to identify and classify software requirement errors ",
journal = "Information and Software Technology ",
volume = "51",
number = "7",
pages = "1087 - 1109",
year = "2009",
note = "Special Section: Software Engineering for Secure SystemsSoftware Engineering for Secure Systems ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2009.01.004",
url = "https://www.sciencedirect.com/science/article/pii/S0950584909000111",
author = "Gursimran Singh Walia and Jeffrey C. Carver",
keywords = "Systematic literature review",
keywords = "Human errors",
keywords = "Software quality ",
abstract = "Most software quality research has focused on identifying faults (i.e., information is incorrectly recorded in an artifact). Because software still exhibits incorrect behavior, a different approach is needed. This paper presents a systematic literature review to develop taxonomy of errors (i.e., the sources of faults) that may occur during the requirements phase of software lifecycle. This taxonomy is designed to aid developers during the requirement inspection process and to improve overall software quality. The review identified 149 papers from the software engineering, psychology and human cognition literature that provide information about the sources of requirements faults. A major result of this paper is a categorization of the sources of faults into a formal taxonomy that provides a starting point for future research into error-based approaches to improving software quality. "
}
@article{Usman201743,
title = "Taxonomies in software engineering: A Systematic mapping study and a revised taxonomy development method ",
journal = "Information and Software Technology ",
volume = "85",
number = "",
pages = "43 - 59",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.01.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917300472",
author = "Muhammad Usman and Ricardo Britto and Jürgen Börstler and Emilia Mendes",
keywords = "Taxonomy",
keywords = "Classification",
keywords = "Software engineering",
keywords = "Systematic mapping study ",
abstract = "Abstract Context: Software Engineering (SE) is an evolving discipline with new subareas being continuously developed and added. To structure and better understand the \{SE\} body of knowledge, taxonomies have been proposed in all \{SE\} knowledge areas. Objective: The objective of this paper is to characterize the state-of-the-art research on \{SE\} taxonomies. Method: A systematic mapping study was conducted, based on 270 primary studies. Results: An increasing number of \{SE\} taxonomies have been published since 2000 in a broad range of venues, including the top \{SE\} journals and conferences. The majority of taxonomies can be grouped into the following \{SWEBOK\} knowledge areas: construction (19.55%), design (19.55%), requirements (15.50%) and maintenance (11.81%). Illustration (45.76%) is the most frequently used approach for taxonomy validation. Hierarchy (53.14%) and faceted analysis (39.48%) are the most frequently used classification structures. Most taxonomies rely on qualitative procedures to classify subject matter instances, but in most cases (86.53%) these procedures are not described in sufficient detail. The majority of the taxonomies (97%) target unique subject matters and many taxonomy-papers are cited frequently. Most \{SE\} taxonomies are designed in an ad-hoc way. To address this issue, we have revised an existing method for developing taxonomies in a more systematic way. Conclusion: There is a strong interest in taxonomies in SE, but few taxonomies are extended or revised. Taxonomy design decisions regarding the used classification structures, procedures and descriptive bases are usually not well described and motivated. "
}
@article{Vale20171,
title = "Software product lines traceability: A systematic mapping study ",
journal = "Information and Software Technology ",
volume = "84",
number = "",
pages = "1 - 18",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2016.12.004",
url = "https://www.sciencedirect.com/science/article/pii/S0950584916304463",
author = "Tassio Vale and Eduardo Santana de Almeida and Vander Alves and Uirá Kulesza and Nan Niu and Ricardo de Lima",
keywords = "Systematic mapping study",
keywords = "Software product lines",
keywords = "Software and systems traceability",
keywords = "Software reuse ",
abstract = "Abstract Context: Traceability in Software Product Lines (SPL) is the ability to interrelate software engineering artifacts through required links to answer specific questions related to the families of products and underlying development processes. Despite the existence of studies to map out available evidence on traceability for single systems development, there is a lack of understanding on common strategies, activities, artifacts, and research gaps for \{SPL\} traceability. Objective: This paper analyzes 62 studies dating from 2001 to 2015 and discusses seven aspects of \{SPL\} traceability: main goals, strategies, application domains, research intensity, research challenges, rigor, and industrial relevance. In addition to the analysis, this paper also synthesizes the available evidence, identifies open issues and points out areas calling for further research. Method: To gather evidence, we defined a mapping study process adapted from existing guidelines. Driven by a set of research questions, this process comprises three major phases: planning, conducting, and documenting the review. Results: This work provides a structured understanding of \{SPL\} traceability, indicating areas for further research. The lack of evidence regarding the application of research methods indicates the need for more rigorous \{SPL\} traceability studies with better description of context, study design, and limitations. For practitioners, although most identified studies have low industrial relevance, a few of them have high relevance and thus could provide some decision making support for application of \{SPL\} traceability in practice. Conclusions: This work concludes that \{SPL\} traceability is maturing and pinpoints areas where further investigation should be performed. As future work, we intend to improve the comparison between traceability proposals for \{SPL\} and single-system development. "
}
@article{GonzálezLadróndeGuevara2016188,
title = "The usage of \{ISBSG\} data fields in software effort estimation: A systematic mapping study ",
journal = "Journal of Systems and Software ",
volume = "113",
number = "",
pages = "188 - 215",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2015.11.040",
url = "https://www.sciencedirect.com/science/article/pii/S0164121215002642",
author = "Fernando González-Ladrón-de-Guevara and Marta Fernández-Diego and Chris Lokan",
keywords = "Systematic mapping study",
keywords = "ISBSG data field",
keywords = "Software effort estimation ",
abstract = "Abstract The International Software Benchmarking Standards Group (ISBSG) maintains a repository of data about completed software projects. A common use of the \{ISBSG\} dataset is to investigate models to estimate a software project's size, effort, duration, and cost. The aim of this paper is to determine which and to what extent variables in the \{ISBSG\} dataset have been used in software engineering to build effort estimation models. For that purpose a systematic mapping study was applied to 107 research papers, obtained after a filtering process, that were published from 2000 until the end of 2013, and which listed the independent variables used in the effort estimation models. The usage of \{ISBSG\} variables for filtering, as dependent variables, and as independent variables is described. The 20 variables (out of 71) mostly used as independent variables for effort estimation are identified and analysed in detail, with reference to the papers and types of estimation methods that used them. We propose guidelines that can help researchers make informed decisions about which \{ISBSG\} variables to select for their effort estimation models. "
}
@article{Shen2011137,
title = "Assessing \{PSP\} effect in training disciplined software development: A Plan–Track–Review model ",
journal = "Information and Software Technology ",
volume = "53",
number = "2",
pages = "137 - 148",
year = "2011",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2010.09.004",
url = "https://www.sciencedirect.com/science/article/pii/S0950584910001710",
author = "Wen-Hsiang Shen and Nien-Lin Hsueh and Wei-Mann Lee",
keywords = "Personal software process (PSP)",
keywords = "Software process improvement (SPI)",
keywords = "Effect assessment",
keywords = "Plan–Track–Review ",
abstract = "Context In training disciplined software development, the \{PSP\} is said to result in such effect as increased estimation accuracy, better software quality, earlier defect detection, and improved productivity. But a systematic mechanism that can be easily adopted to assess and interpret \{PSP\} effect is scarce within the existing literature. Objective The purpose of this study is to explore the possibility of devising a feasible assessment model that ties up critical software engineering values with the pertinent \{PSP\} metrics. Method A systematic review of the literature was conducted to establish such an assessment model (we called a Plan–Track–Review model). Both mean and median approaches along with a set of simplified procedures were used to assess the commonly accepted \{PSP\} training effects. A set of statistical analyses further followed to increase understanding of the relationships among the \{PSP\} metrics and to help interpret the application results. Results Based on the results of this study, \{PSP\} training effect on the controllability, manageability, and reliability of a software engineer is quite positive and largely consistent with the literature. However, its effect on one’s predictability on project in general (and on project size in particular) is not implied as said in the literature. As for one’s overall project efficiency, our results show a moderate improvement. Our initial finding also suggests that a prior stage \{PSP\} effect could have an impact on later stage training outcomes. Conclusion It is concluded that this Plan–Track–Review model with the associated framework can be used to assess \{PSP\} effect regarding a disciplined software development. The generated summary report serves to provide useful feedback for both \{PSP\} instructors and students based on internal as well as external standards. "
}
@article{Zein2016334,
title = "A systematic mapping study of mobile application testing techniques ",
journal = "Journal of Systems and Software ",
volume = "117",
number = "",
pages = "334 - 356",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2016.03.065",
url = "https://www.sciencedirect.com/science/article/pii/S0164121216300140",
author = "Samer Zein and Norsaremah Salleh and John Grundy",
keywords = "Systematic mapping",
keywords = "Mobile application testing",
keywords = "Software testing ",
abstract = "Abstract The importance of mobile application specific testing techniques and methods has been attracting much attention of software engineers over the past few years. This is due to the fact that mobile applications are different than traditional web and desktop applications, and more and more they are moving to being used in critical domains. Mobile applications require a different approach to application quality and dependability and require an effective testing approach to build high quality and more reliable software. We performed a systematic mapping study to categorize and to structure the research evidence that has been published in the area of mobile application testing techniques and challenges that they have reported. Seventy nine (79) empirical studies are mapped to a classification schema. Several research gaps are identified and specific key testing issues for practitioners are identified: there is a need for eliciting testing requirements early during development process; the need to conduct research in real-world development environments; specific testing techniques targeting application life-cycle conformance and mobile services testing; and comparative studies for security and usability testing. "
}
@article{Tofan2014850,
title = "Past and future of software architectural decisions – A systematic mapping study ",
journal = "Information and Software Technology ",
volume = "56",
number = "8",
pages = "850 - 872",
year = "2014",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.03.009",
url = "https://www.sciencedirect.com/science/article/pii/S0950584914000706",
author = "Dan Tofan and Matthias Galster and Paris Avgeriou and Wes Schuitema",
keywords = "Software architecture",
keywords = "Architectural decisions",
keywords = "Systematic mapping study ",
abstract = "AbstractContext The software architecture of a system is the result of a set of architectural decisions. The topic of architectural decisions in software engineering has received significant attention in recent years. However, no systematic overview exists on the state of research on architectural decisions. Objective The goal of this study is to provide a systematic overview of the state of research on architectural decisions. Such an overview helps researchers reflect on previous research and plan future research. Furthermore, such an overview helps practitioners understand the state of research, and how research results can help practitioners in their architectural decision-making. Method We conducted a systematic mapping study, covering studies published between January 2002 and January 2012. We defined six research questions. We queried six reference databases and obtained an initial result set of 28,895 papers. We followed a search and filtering process that resulted in 144 relevant papers. Results After classifying the 144 relevant papers for each research question, we found that current research focuses on documenting architectural decisions. We found that only several studies describe architectural decisions from the industry. We identified potential future research topics: domain-specific architectural decisions (such as mobile), achieving specific quality attributes (such as reliability or scalability), uncertainty in decision-making, and group architectural decisions. Regarding empirical evaluations of the papers, around half of the papers use systematic empirical evaluation approaches (such as surveys, or case studies). Still, few papers on architectural decisions use experiments. Conclusion Our study confirms the increasing interest in the topic of architectural decisions. This study helps the community reflect on the past ten years of research on architectural decisions. Researchers are offered a number of promising future research directions, while practitioners learn what existing papers offer. "
}
@article{FernándezDiego2014527,
title = "Potential and limitations of the \{ISBSG\} dataset in enhancing software engineering research: A mapping review ",
journal = "Information and Software Technology ",
volume = "56",
number = "6",
pages = "527 - 544",
year = "2014",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2014.01.003",
url = "https://www.sciencedirect.com/science/article/pii/S0950584914000147",
author = "Marta Fernández-Diego and Fernando González-Ladrón-de-Guevara",
keywords = "Systematic mapping study",
keywords = "Research methods",
keywords = "Software engineering",
keywords = "ISBSG",
keywords = "Software effort estimation",
keywords = "Software cost prediction ",
abstract = "AbstractContext The International Software Benchmarking Standards Group (ISBSG) maintains a software development repository with over 6000 software projects. This dataset makes it possible to estimate a project’s size, effort, duration, and cost. Objective The aim of this study was to determine how and to what extent, \{ISBSG\} has been used by researchers from 2000, when the first papers were published, until June of 2012. Method A systematic mapping review was used as the research method, which was applied to over 129 papers obtained after the filtering process. Results The papers were published in 19 journals and 40 conferences. Thirty-five percent of the papers published between years 2000 and 2011 have received at least one citation in journals and only five papers have received six or more citations. Effort variable is the focus of 70.5% of the papers, 22.5% center their research in a variable different from effort and 7% do not consider any target variable. Additionally, in as many as 70.5% of papers, effort estimation is the research topic, followed by dataset properties (36.4%). The more frequent methods are Regression (61.2%), Machine Learning (35.7%), and Estimation by Analogy (22.5%). \{ISBSG\} is used as the only support in 55% of the papers while the remaining papers use complementary datasets. The \{ISBSG\} release 10 is used most frequently with 32 references. Finally, some benefits and drawbacks of the usage of \{ISBSG\} have been highlighted. Conclusion This work presents a snapshot of the existing usage of \{ISBSG\} in software development research. \{ISBSG\} offers a wealth of information regarding practices from a wide range of organizations, applications, and development types, which constitutes its main potential. However, a data preparation process is required before any analysis. Lastly, the potential of \{ISBSG\} to develop new research is also outlined. "
}
@article{Pernstål20132797,
title = "The lean gap: A review of lean approaches to large-scale software systems development ",
journal = "Journal of Systems and Software ",
volume = "86",
number = "11",
pages = "2797 - 2821",
year = "2013",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2013.06.035",
url = "https://www.sciencedirect.com/science/article/pii/S0164121213001477",
author = "J. Pernstål and R. Feldt and T. Gorschek",
keywords = "Systematic mapping study",
keywords = "Software engineering",
keywords = "Lean product development",
keywords = "Lean software development",
keywords = "Agile software development",
keywords = "Automotive software development ",
abstract = "Abstract Lean approaches to product development (LPD) have had a strong influence on many industries and in recent years there have been many proponents for lean in software development as it can support the increasing industry need of scaling agile software development. With it's roots in industrial manufacturing and, later, industrial product development, it would seem natural that \{LPD\} would adapt well to large-scale development projects of increasingly software-intensive products, such as in the automotive industry. However, it is not clear what kind of experience and results have been reported on the actual use of lean principles and practices in software development for such large-scale industrial contexts. This was the motivation for this study as the context was an ongoing industry process improvement project at Volvo Car Corporation and Volvo Truck Corporation. The objectives of this study are to identify and classify state of the art in large-scale software development influenced by \{LPD\} approaches and use this established knowledge to support industrial partners in decisions on a software process improvement (SPI) project, and to reveal research gaps and proposed extensions to \{LPD\} in relation to its well-known principles and practices. For locating relevant state of the art we conducted a systematic mapping study, and the industrial applicability and relevance of results and said extensions to \{LPD\} were further analyzed in the context of an actual, industrial case. A total of 10,230 papers were found in database searches, of which 38 papers were found relevant. Of these, only 42 percent clearly addressed large-scale development. Furthermore, a majority of papers (76 percent) were non-empirical and many lacked information about study design, context and/or limitations. Most of the identified results focused on eliminating waste and creating flow in the software development process, but there was a lack of results for other \{LPD\} principles and practices. Overall, it can be concluded that research in the much hyped field of lean software development is in its nascent state when it comes to large scale development. There is very little support available for practitioners who want to apply lean approaches for improving large-scale software development, especially when it comes to inter-departmental interactions during development. This paper explicitly maps the area, qualifies available research, and identifies gaps, as well as suggests extensions to lean principles relevant for large scale development of software intensive systems. "
}
@article{Wendler20121317,
title = "The maturity of maturity model research: A systematic mapping study ",
journal = "Information and Software Technology ",
volume = "54",
number = "12",
pages = "1317 - 1339",
year = "2012",
note = "Special Section on Software Reliability and Security ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2012.07.007",
url = "https://www.sciencedirect.com/science/article/pii/S0950584912001334",
author = "Roy Wendler",
keywords = "Maturity models",
keywords = "Software management",
keywords = "Design-oriented research",
keywords = "Systematic mapping study ",
abstract = "Context Maturity models offer organizations a simple but effective possibility to measure the quality of their processes. Emerged out of software engineering, the application fields have widened and maturity model research is becoming more important. During the last two decades the publication amount steadily rose as well. Until today, no studies have been available summarizing the activities and results of the field of maturity model research. Objective The objective of this paper is to structure and analyze the available literature of the field of maturity model research to identify the state-of-the-art research as well as research gaps. Method A systematic mapping study was conducted. It included relevant publications of journals and \{IS\} conferences. Mapping studies are a suitable method for structuring a broad research field concerning research questions about contents, methods, and trends in the available publications. Results The mapping of 237 articles showed that current maturity model research is applicable to more than 20 domains, heavily dominated by software development and software engineering. The study revealed that most publications deal with the development of maturity models and empirical studies. Theoretical reflective publications are scarce. Furthermore, the relation between conceptual and design-oriented maturity model development was analyzed, indicating that there is still a gap in evaluating and validating developed maturity models. Finally, a comprehensive research framework was derived from the study results and implications for further research are given. Conclusion The mapping study delivers the first systematic summary of maturity model research. The categorization of available publications helps researchers gain an overview of the state-of-the-art research and current research gaps. The proposed research framework supports researchers categorizing their own projects. In addition, practitioners planning to use a maturity model may use the study as starting point to identify which maturity models are suitable for their domain and where limitations exist. "
}
@article{Kasoju20131237,
title = "Analyzing an automotive testing process with evidence-based software engineering ",
journal = "Information and Software Technology ",
volume = "55",
number = "7",
pages = "1237 - 1259",
year = "2013",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2013.01.005",
url = "https://www.sciencedirect.com/science/article/pii/S0950584913000165",
author = "Abhinaya Kasoju and Kai Petersen and Mika V. Mäntylä",
keywords = "Evidence-based software engineering",
keywords = "Process assessment",
keywords = "Automotive software testing ",
abstract = "Context Evidence-based software engineering (EBSE) provides a process for solving practical problems based on a rigorous research approach. The primary focus so far was on mapping and aggregating evidence through systematic reviews. Objectives We extend existing work on evidence-based software engineering by using the \{EBSE\} process in an industrial case to help an organization to improve its automotive testing process. With this we contribute in (1) providing experiences on using evidence based processes to analyze a real world automotive test process and (2) provide evidence of challenges and related solutions for automotive software testing processes. Methods In this study we perform an in-depth investigation of an automotive test process using an extended \{EBSE\} process including case study research (gain an understanding of practical questions to define a research scope), systematic literature review (identify solutions through systematic literature), and value stream mapping (map out an improved automotive test process based on the current situation and improvement suggestions identified). These are followed by reflections on the \{EBSE\} process used. Results In the first step of the \{EBSE\} process we identified 10 challenge areas with a total of 26 individual challenges. For 15 out of those 26 challenges our domain specific systematic literature review identified solutions. Based on the input from the challenges and the solutions, we created a value stream map of the current and future process. Conclusions Overall, we found that the evidence-based process as presented in this study helps in technology transfer of research results to industry, but at the same time some challenges lie ahead (e.g. scoping systematic reviews to focus more on concrete industry problems, and understanding strategies of conducting \{EBSE\} with respect to effort and quality of the evidence). "
}
@article{Prikladnicki2010779,
title = "Process models in the practice of distributed software development: A systematic review of the literature ",
journal = "Information and Software Technology ",
volume = "52",
number = "8",
pages = "779 - 791",
year = "2010",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2010.03.009",
url = "https://www.sciencedirect.com/science/article/pii/S0950584910000492",
author = "Rafael Prikladnicki and Jorge Luis Nicolas Audy",
keywords = "Distributed software development",
keywords = "Global software engineering",
keywords = "Offshoring",
keywords = "Process models",
keywords = "Process improvement ",
abstract = "Context Distributed Software Development (DSD) has recently become an active research area. Although considerable research effort has been made in this area, as yet, no agreement has been reached as to an appropriate process model for DSD. Purpose This paper is intended to identify and synthesize papers that describe process models for distributed software development in the context of overseas outsourcing, i.e. “offshoring”. Method We used a systematic review methodology to search seven digital libraries and one topic-specific conference. Results We found 27 primary studies describing stage-related \{DSD\} process models. Only five of such studies looked into outsourcing to a subsidiary company (i.e. “internal offshoring”). Nineteen primary studies addressed the need for \{DSD\} process models. Eight primary studies and three literature surveys described stage-based \{DSD\} process models, but only three of such models were empirically evaluated. Conclusion We need more research aimed at internal offshoring. Furthermore, proposed models need to be empirically validated. "
}
@article{Staples2008605,
title = "Systematic review of organizational motivations for adopting CMM-based \{SPI\} ",
journal = "Information and Software Technology ",
volume = "50",
number = "7–8",
pages = "605 - 620",
year = "2008",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2007.07.003",
url = "https://www.sciencedirect.com/science/article/pii/S0950584907000778",
author = "Mark Staples and Mahmood Niazi",
keywords = "CMM",
keywords = "CMMI",
keywords = "Capability Maturity Model",
keywords = "Software Process Improvement ",
abstract = "Background: Software Process Improvement (SPI) is intended to improve software engineering, but can only be effective if used. To improve SPI’s uptake, we should understand why organizations adopt SPI. CMM-based \{SPI\} approaches are widely known and studied. Objective: We investigated why organizations adopt CMM-based \{SPI\} approaches, and how these motivations relate to organizations’ size. Method: We performed a systematic review, examining reasons reported in more than forty primary studies. Results: Reasons usually related to product quality and project performance, and less commonly, to process. Organizations reported customer reasons infrequently and employee reasons very rarely. We could not show that reasons related to size. Conclusion: Despite its origins in helping to address customer-related issues for the USAF, CMM-based \{SPI\} has mostly been adopted to help organizations improve project performance and product quality issues. This reinforces a view that the goal of \{SPI\} is not to improve process per se, but instead to provide business benefits. "
}
@article{Murugesan20151,
title = "Design criteria for visualization of energy consumption: A systematic literature review ",
journal = "Sustainable Cities and Society ",
volume = "18",
number = "",
pages = "1 - 12",
year = "2015",
note = "",
issn = "2210-6707",
doi = "https://doi.org/10.1016/j.scs.2015.04.009",
url = "https://www.sciencedirect.com/science/article/pii/S2210670715000499",
author = "Latha Karthigaa Murugesan and Rashina Hoda and Zoran Salcic",
keywords = "Visualization",
keywords = "Energy",
keywords = "Grounded Theory ",
abstract = "Abstract Visualizing energy consumption is widely considered an important way to motivate end-users to conserve energy. Designing effective visualizations, however, is a non-trivial software design challenge. In particular, there are no clear criteria for designing visualizations of energy consumption for end-users. This paper presents systematic literature review findings from a total of 22 primary studies selected after applying quality and relevance filters. The results were synthesized using Grounded Theory's open coding and constant comparison procedures and led to the emergence of design criteria for visualization as the central theme across all primary studies. The key categories comprising this central theme include: (a) functional criteria, which include information displayed in the visualization, modes of visualization, and visualization techniques, and (b) non-functional criteria, which include hardware and software considerations such as integrality, extensibility and portability. Together, these criteria provide clear guidelines based on research evidence for software engineers and researchers designing visualizations of energy consumption for end-users. "
}
@article{Kitchenham2012804,
title = "Three empirical studies on the agreement of reviewers about the quality of software engineering experiments ",
journal = "Information and Software Technology ",
volume = "54",
number = "8",
pages = "804 - 819",
year = "2012",
note = "Special Issue: Voice of the Editorial BoardSpecial Issue: Voice of the Editorial Board ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2011.11.008",
url = "https://www.sciencedirect.com/science/article/pii/S0950584911002321",
author = "Barbara Ann Kitchenham and Dag I.K. Sjøberg and Tore Dybå and Dietmar Pfahl and Pearl Brereton and David Budgen and Martin Höst and Per Runeson",
keywords = "Quality evaluation",
keywords = "Empirical studies",
keywords = "Human-intensive experiments",
keywords = "Experimentation",
keywords = "Software engineering ",
abstract = "Context During systematic literature reviews it is necessary to assess the quality of empirical papers. Current guidelines suggest that two researchers should independently apply a quality checklist and any disagreements must be resolved. However, there is little empirical evidence concerning the effectiveness of these guidelines. Aims This paper investigates the three techniques that can be used to improve the reliability (i.e. the consensus among reviewers) of quality assessments, specifically, the number of reviewers, the use of a set of evaluation criteria and consultation among reviewers. We undertook a series of studies to investigate these factors. Method Two studies involved four research papers and eight reviewers using a quality checklist with nine questions. The first study was based on individual assessments, the second study on joint assessments with a period of inter-rater discussion. A third more formal randomised block experiment involved 48 reviewers assessing two of the papers used previously in teams of one, two and three persons to assess the impact of discussion among teams of different size using the evaluations of the “teams” of one person as a control. Results For the first two studies, the inter-rater reliability was poor for individual assessments, but better for joint evaluations. However, the results of the third study contradicted the results of Study 2. Inter-rater reliability was poor for all groups but worse for teams of two or three than for individuals. Conclusions When performing quality assessments for systematic literature reviews, we recommend using three independent reviewers and adopting the median assessment. A quality checklist seems useful but it is difficult to ensure that the checklist is both appropriate and understood by reviewers. Furthermore, future experiments should ensure participants are given more time to understand the quality checklist and to evaluate the research papers. "
}
@article{Hoisl201749,
title = "Reusable and generic design decisions for developing UML-based domain-specific languages ",
journal = "Information and Software Technology ",
volume = "92",
number = "",
pages = "49 - 74",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.07.008",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917304536",
author = "Bernhard Hoisl and Stefan Sobernig and Mark Strembeck",
keywords = "Model-driven software development",
keywords = "Domain-specific language",
keywords = "Design decision",
keywords = "Design rationale",
keywords = "Unified modeling language",
keywords = "Survey ",
abstract = "Abstract Context: In recent years, UML-based domain-specific model languages (DSMLs) have become a popular option in model-driven development projects. However, making informed design decisions for such \{DSMLs\} involves a large number of non-trivial and inter-related options. These options concern the language-model specification, \{UML\} extension techniques, concrete-syntax language design, and modeling-tool support. Objective: In order to make the corresponding knowledge on design decisions reusable, proven design rationale from existing \{DSML\} projects must be collected, systematized, and documented using an agreed upon documentation format. Method: We applied a sequential multi-method approach to identify and to document reusable design decisions for UML-based DSMLs. The approach included a Web-based survey with 80 participants. Moreover, 80 \{DSML\} projects11 Note that it is pure coincidence that there were 80 participants in the survey and that 80 \{DSML\} projects were reviewed. , which have been identified through a prior systematic literature review, were analyzed in detail in order to identify reusable design decisions for such DSMLs. Results: We present insights on the current state of practice in documenting UML-based \{DSMLs\} (e.g., perceived barriers, documentation techniques, reuse potential) and a publicly available collection of reusable design decisions, including 35 decision options on different \{DSML\} development concerns (especially concerning the language model, concrete-syntax language design, and modeling tools). The reusable design decisions are documented using a structured documentation format (decision record). Conclusion: Our results are both, scientifically relevant (e.g. for design-space analyses or for creating classification schemas for further research on UML-based \{DSML\} development) and important for actual software engineering projects (e.g. by providing best-practice guidelines and pointers to common pitfalls). "
}
@article{Malhotra201785,
title = "On the application of search-based techniques for software engineering predictive modeling: A systematic review and future directions ",
journal = "Swarm and Evolutionary Computation ",
volume = "32",
number = "",
pages = "85 - 109",
year = "2017",
note = "",
issn = "2210-6502",
doi = "https://doi.org/10.1016/j.swevo.2016.10.002",
url = "https://www.sciencedirect.com/science/article/pii/S2210650216303418",
author = "Ruchika Malhotra and Megha Khanna and Rajeev R. Raje",
keywords = "Search-based techniques",
keywords = "Change prediction",
keywords = "Defect prediction",
keywords = "Effort estimation",
keywords = "Maintainability prediction",
keywords = "Software quality ",
abstract = "Abstract Software engineering predictive modeling involves construction of models, with the help of software metrics, for estimating quality attributes. Recently, the use of search-based techniques have gained importance as they help the developers and project-managers in the identification of optimal solutions for developing effective prediction models. In this paper, we perform a systematic review of 78 primary studies from January 1992 to December 2015 which analyze the predictive capability of search-based techniques for ascertaining four predominant software quality attributes, i.e., effort, defect proneness, maintainability and change proneness. The review analyses the effective use and application of search-based techniques by evaluating appropriate specifications of fitness functions, parameter settings, validation methods, accounting for their stochastic natures and the evaluation of developmental models with the use of well-known statistical tests. Furthermore, we compare the effectiveness of different models, developed using the various search-based techniques amongst themselves, and also with the prevalent machine learning techniques used in literature. Although there are very few studies which use search-based techniques for predicting maintainability and change proneness, we found that the results of the application of search-based techniques for effort estimation and defect prediction are encouraging. Hence, this comprehensive study and the associated results will provide guidelines to practitioners and researchers and will enable them to make proper choices for applying the search-based techniques to their specific situations. "
}
@article{Neiva2016137,
title = "Towards pragmatic interoperability to support collaboration: A systematic review and mapping of the literature ",
journal = "Information and Software Technology ",
volume = "72",
number = "",
pages = "137 - 150",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.12.013",
url = "https://www.sciencedirect.com/science/article/pii/S0950584916000021",
author = "Frâncila Weidt Neiva and José Maria N. David and Regina Braga and Fernanda Campos",
keywords = "Pragmatic interoperability",
keywords = "Collaboration",
keywords = "Collaborative systems",
keywords = "Groupware",
keywords = "Interoperability ",
abstract = "Abstract Context: Many researchers have argued that providing interoperability support only considering the format and meaning (i.e. syntax and semantic) of data exchange is not enough to achieve complete, effective and meaningful collaboration. Pragmatic interoperability has been highlighted as a key requirement to enhance collaboration. However, fulfilling this requirement is not a trivial task and there is a lack of works discussing solutions to achieve this level of interoperability. Objectives: The aim of this study is to present a systematic review and mapping of the literature in order to identify, analyse and classify the published solutions to achieve pragmatic interoperability. Method: To conduct a systematic review and mapping in accordance with the guidelines proposed in the evidence-based software engineering literature. Results: Our study identified 13 papers reporting pragmatic interoperability computational solutions. The first paper in our set of selected papers was published in 2004; the main strategies used to address pragmatic interoperability issues were service discovery, composition and/or selection and ontologies. The application domain of the identified solutions was mainly e-business. In addition, most of the identified solutions were software architectures. Conclusion: Mature proposals addressing pragmatic interoperability are still rare in the literature. Although many works have discussed the importance of pragmatic interoperability, it is necessary that researchers report solutions that implement and evaluate pragmatic interoperability in order to make progress in this area. "
}
@article{Febrero201618,
title = "Software reliability modeling based on ISO/IEC \{SQuaRE\} ",
journal = "Information and Software Technology ",
volume = "70",
number = "",
pages = "18 - 29",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.09.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915001652",
author = "Felipe Febrero and Coral Calero and M. Ángeles Moraga",
keywords = "Software quality",
keywords = "Software reliability modeling",
keywords = "International standard",
keywords = "SQuaRE ",
abstract = "AbstractContext The increasing dependence of our society on software driven systems has led Software Reliability to become a key factor as well as making it a highly active research area with hundreds of works being published every year. It would, however, appear that this activity is much more reduced as regards how to apply representative international standards on Product Quality to industrial environments, with just a few works on Standard Based software reliability modeling (SB-SRM). This is surprising given the relevance of such International Standards in industry. Objective To identify and analyze the existing works on the modeling of Software Reliability based on International Standards as the starting point for a reliability assessment proposal based on ISO/IEC-25000 “Software Product Quality Requirements and Evaluation” (SQuaRE) series. Method The work methodology is based on the guidelines provided in Evidence Based Software Engineering for Systematic Literature Reviews (SLR). Results A total of 1820 works were obtained as a result of the \{SLR\} search, more than 800 primary studies were selected after data filtering. After scrutiny, over thirty of those were thoroughly analyze, the results obtained show a very limited application of SB-SRM particularly to industrial environment. Conclusion Our analysis point to the complexity of the proposed models together with the difficulties involved in applying them to the management of engineering activities as a root cause to be considered for such limited application. The various stakeholder needs are also a point of paramount importance that should be better covered if the industrial applicability of the proposed models is to be increased. "
}
@article{Sobernig2016140,
title = "Extracting reusable design decisions for UML-based domain-specific languages: A multi-method study ",
journal = "Journal of Systems and Software ",
volume = "113",
number = "",
pages = "140 - 172",
year = "2016",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2015.11.037",
url = "https://www.sciencedirect.com/science/article/pii/S0164121215002617",
author = "Stefan Sobernig and Bernhard Hoisl and Mark Strembeck",
keywords = "Domain-specific language",
keywords = "Unified modeling language",
keywords = "Design decision",
keywords = "Design rationale",
keywords = "Domain-specific modeling",
keywords = "Model-driven development ",
abstract = "Abstract When developing domain-specific modeling languages (DSMLs), software engineers have to make a number of important design decisions on the \{DSML\} itself, or on the software-development process that is applied to develop the DSML. Thus, making well-informed design decisions is a critical factor in developing DSMLs. To support this decision-making process, the model-driven development community has started to collect established design practices in terms of patterns, guidelines, story-telling, and procedural models. However, most of these documentation practices do not capture the details necessary to reuse the rationale behind these decisions in other \{DSML\} projects. In this paper, we report on a three-year research effort to compile and to empirically validate a catalog of structured decision descriptions (decision records) for UML-based DSMLs. This catalog is based on design decisions extracted from 90 \{DSML\} projects. These projects were identified—among others—via an extensive systematic literature review (SLR) for the years 2005–2012. Based on more than 8,000 candidate publications, we finally selected 84 publications for extracting design-decision data. The extracted data were evaluated quantitatively using a frequent-item-set analysis to obtain characteristic combinations of design decisions and qualitatively to document recurring documentation issues for UML-based DSMLs. We revised the collected decision records based on this evidence and made the decision-record catalog for developing UML-based \{DSMLs\} publicly available. Furthermore, our study offers insights into \{UML\} usage (e.g. diagram types) and into the adoption of \{UML\} extension techniques (e.g. metamodel extensions, profiles). "
}
@article{Morschheuser2017,
title = "How to design gamification? A method for engineering gamified software ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.10.015",
url = "https://www.sciencedirect.com/science/article/pii/S095058491730349X",
author = "Benedikt Morschheuser and Lobna Hassan and Karl Werder and Juho Hamari",
keywords = "Gamification",
keywords = "Software engineering",
keywords = "Design science research",
keywords = "Persuasive technology",
keywords = "Gameful design",
keywords = "Playfulness",
keywords = "Game design ",
abstract = "AbstractContext Since its inception around 2010, gamification has become one of the top technology and software trends. However, gamification has also been regarded as one of the most challenging areas of software engineering. Beyond traditional software design requirements, designing gamification requires the command of disciplines such as (motivational/behavioral) psychology, game design, and narratology, making the development of gamified software a challenge for traditional software developers. Gamification software inhabits a finely tuned niche of software engineering that seeks for both high functionality and engagement; beyond technical flawlessness, gamification has to motivate and affect users. Consequently, it has also been projected that most gamified software is doomed to fail. Objective This paper seeks to advance the understanding of designing gamification and to provide a comprehensive method for developing gamified software. Method We approach the research problem via a design science research approach; firstly, by synthesizing the current body of literature on gamification design methods and by interviewing 25 gamification experts, producing a comprehensive list of design principles for developing gamified software. Secondly, and more importantly, we develop a detailed method for engineering of gamified software based on the gathered knowledge and design principles. Finally, we conduct an evaluation of the artifacts via interviews of ten gamification experts and implementation of the engineering method in a gamification project. Results As results of the study, we present the method and key design principles for engineering gamified software. Based on the empirical and expert evaluation, the developed method was deemed as comprehensive, implementable, complete, and useful. We deliver a comprehensive overview of gamification guidelines and shed novel insights into the nature of gamification development and design discourse. Conclusion This paper takes first steps towards a comprehensive method for gamified software engineering. "
}
@incollection{Putz1993363,
title = "A \{DEVELOPMENT\} \{METHODOLOGY\} \{FOR\} \{SPACE\} A&amp;R \{CONTROL\} \{SYSTEMS\} ",
editor = "DeBRA, D.B.  and GOTTZEIN, E. ",
booktitle = "Automatic Control in Aerospace 1992 ",
publisher = "Pergamon",
edition = "",
address = "Oxford",
year = "1993",
pages = "363 - 368",
series = "IFAC Symposia Series",
isbn = "978-0-08-041715-8",
doi = "https://doi.org/10.1016/B978-0-08-041715-8.50052-3",
url = "https://www.sciencedirect.com/science/article/pii/B9780080417158500523",
author = "P. Putz and A. Elfving",
abstract = "Keywords. Hierarchically intelligent control, control architectures, reference models, control system synthesis, control system requirements analysis, robots, software tools "
}
@article{Sharafi201579,
title = "A systematic literature review on the usage of eye-tracking in software engineering ",
journal = "Information and Software Technology ",
volume = "67",
number = "",
pages = "79 - 107",
year = "2015",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.06.008",
url = "https://www.sciencedirect.com/science/article/pii/S0950584915001196",
author = "Zohreh Sharafi and Zéphyrin Soh and Yann-Gaël Guéhéneuc",
keywords = "Eye-tracking",
keywords = "Software engineering",
keywords = "Experiment ",
abstract = "AbstractContext Eye-tracking is a mean to collect evidence regarding some participants’ cognitive processes. Eye-trackers monitor participants’ visual attention by collecting eye-movement data. These data are useful to get insights into participants’ cognitive processes during reasoning tasks. Objective The Evidence-based Software Engineering (EBSE) paradigm has been proposed in 2004 and, since then, has been used to provide detailed insights regarding different topics in software engineering research and practice. Systematic Literature Reviews (SLR) are also useful in the context of \{EBSE\} by bringing together all existing evidence of research and results about a particular topic. This \{SLR\} evaluates the current state of the art of using eye-trackers in software engineering and provides evidence on the uses and contributions of eye-trackers to empirical studies in software engineering. Method We perform a \{SLR\} covering eye-tracking studies in software engineering published from 1990 up to the end of 2014. To search all recognised resources, instead of applying manual search, we perform an extensive automated search using Engineering Village. We identify 36 relevant publications, including nine journal papers, two workshop papers, and 25 conference papers. Results The software engineering community started using eye-trackers in the 1990s and they have become increasingly recognised as useful tools to conduct empirical studies from 2006. We observe that researchers use eye-trackers to study model comprehension, code comprehension, debugging, collaborative interaction, and traceability. Moreover, we find that studies use different metrics based on eye-movement data to obtain quantitative measures. We also report the limitations of current eye-tracking technology, which threaten the validity of previous studies, along with suggestions to mitigate these limitations. Conclusion However, not withstanding these limitations and threats, we conclude that the advent of new eye-trackers makes the use of these tools easier and less obtrusive and that the software engineering community could benefit more from this technology. "
}
@article{Putz1992363,
title = "A Development Methodology for Space A&amp;R Control Systems ",
journal = "\{IFAC\} Proceedings Volumes ",
volume = "25",
number = "22",
pages = "363 - 368",
year = "1992",
note = "12th \{IFAC\} Symposium on Automatic Control in Aerospace 1992, Ottobrun, Germany, 7-11 September ",
issn = "1474-6670",
doi = "https://doi.org/10.1016/S1474-6670(17)49674-1",
url = "https://www.sciencedirect.com/science/article/pii/S1474667017496741",
author = "P. Putz and A. Elfving",
keywords = "Hierarchically intelligent control",
keywords = "control architectures",
keywords = "reference models",
keywords = "control system synthesis",
keywords = "control system requirements analysis",
keywords = "robots",
keywords = "software tools ",
abstract = "Abstract In an effort to support the development of flexible space Automation and Robotics (A&amp;R) systems, the European Space Agency \{ESA\} has begun to establish an A&amp;R Control Development Methodology (CDM). The \{CDM\} encompasses guidelines for the design of control systems to accomplish inter-project unification (for the parallel development of systems with common functionality) and intra-project traceability (to account for evolving requirements and technological capabilities for a given A&amp;R system). The \{CDM\} calls for a phased analysis and development approach to progress from user requirements to hardware and software implementations. A main focus is on a systematic structure of the requirements in order to clearly separate functional, application, operational, and implementational influences. Prime constituents are a solution independent Activity Analysis framework, a Functional Reference Model as the generic logical model of A&amp;R control system architectures, a scheme to capture the function allocation decisions for given operational modes, and guidelines for deliverables and reviews throughout the different phases. Work along the \{CDM\} can be very well supported by existing computer-aided software engineering (CASE) tools. "
}
@article{Lindoerfer2017147,
title = "Enhancing requirements engineering for patient registry software systems with evidence-based components ",
journal = "Journal of Biomedical Informatics ",
volume = "71",
number = "",
pages = "147 - 153",
year = "2017",
note = "",
issn = "1532-0464",
doi = "https://doi.org/10.1016/j.jbi.2017.05.013",
url = "https://www.sciencedirect.com/science/article/pii/S1532046417301090",
author = "Doris Lindoerfer and Ulrich Mansmann",
keywords = "Checklist",
keywords = "Patient registry software system",
keywords = "Technical requirements",
keywords = "Evidence-based requirements engineering ",
abstract = "AbstractIntroduction Patient registries are instrumental for medical research. Often their structures are complex and their implementations use composite software systems to meet the wide spectrum of challenges. Commercial and open-source systems are available for registry implementation, but many research groups develop their own systems. Methodological approaches in the selection of software as well as the construction of proprietary systems are needed. We propose an evidence-based checklist, summarizing essential items for patient registry software systems (CIPROS), to accelerate the requirements engineering process. Methods Requirements engineering activities for software systems follow traditional software requirements elicitation methods, general software requirements specification (SRS) templates, and standards. We performed a multistep procedure to develop a specific evidence-based \{CIPROS\} checklist: (1) A systematic literature review to build a comprehensive collection of technical concepts, (2) a qualitative content analysis to define a catalogue of relevant criteria, and (3) a checklist to construct a minimal appraisal standard. Results \{CIPROS\} is based on 64 publications and covers twelve sections with a total of 72 items. \{CIPROS\} also defines software requirements. Comparing \{CIPROS\} with traditional software requirements elicitation methods, \{SRS\} templates and standards show a broad consensus but differences in issues regarding registry-specific aspects. Discussion Using an evidence-based approach to requirements engineering for registry software adds aspects to the traditional methods and accelerates the software engineering process for registry software. The method we used to construct \{CIPROS\} serves as a potential template for creating evidence-based checklists in other fields. Conclusion The \{CIPROS\} list supports developers in assessing requirements for existing systems and formulating requirements for their own systems, while strengthening the reporting of patient registry software system descriptions. It may be a first step to create standards for patient registry software system assessments. "
}
@article{TorrecillaSalinas201692,
title = "Agile, Web Engineering and Capability Maturity Model Integration: A systematic literature review. ",
journal = "Information and Software Technology ",
volume = "71",
number = "",
pages = "92 - 107",
year = "2016",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2015.11.002",
url = "https://www.sciencedirect.com/science/article/pii/S095058491500186X",
author = "C.J. Torrecilla-Salinas and J. Sedeño and M.J. Escalona and M. Mejías",
keywords = "Agile",
keywords = "Scrum",
keywords = "Web Engineering",
keywords = "CMMI",
keywords = "Software Engineering ",
abstract = "AbstractContext Agile approaches are an alternative for organizations developing software, particularly for those who develop Web applications. Besides, \{CMMI\} (Capability Maturity Model Integration) models are well-established approaches focused on assessing the maturity of an organization that develops software. Web Engineering is the field of Software Engineering responsible for analyzing and studying the specific characteristics of the Web. The suitability of an Agile approach to help organizations reach a certain \{CMMI\} maturity level in Web environments will be very interesting, as they will be able to keep the ability to quickly react and adapt to changes as long as their development processes get mature. Objective This paper responds to whether it is feasible or not, for an organization developing Web systems, to achieve a certain maturity level of the CMMI-DEV model using Agile methods. Method The proposal is analyzed by means of a systematic literature review of the relevant approaches in the field, defining a characterization schema in order to compare them to introduce the current state-of-the-art. Results The results achieved after the systematic literature review are presented, analyzed and compared against the defined schema, extracting relevant conclusions for the different dimensions of the problem: compatibility, compliance, experience, maturity and Web. Conclusion It is concluded that although the definition of an Agile approach to meet the different \{CMMI\} maturity levels goals could be possible for an organization developing Web systems, there is still a lack of detailed studies and analysis on the field. "
}
@article{Souza2017,
title = "A systematic mapping study on game-related methods for software engineering education ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.09.014",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917303518",
author = "Mauricio R. de A. Souza and Lucas Veado and Renata Teles Moreira and Eduardo Figueiredo and Heitor Costa",
keywords = "Software engineering education",
keywords = "Game-based learning",
keywords = "Gamification",
keywords = "Game development based learning ",
abstract = "AbstractContext The use of games in software engineering education is not new. However, recent technologies have provided new opportunities for using games and their elements to enhance learning and student engagement. Objective The goal of this paper is twofold. First, we discuss how game-related methods have been used in the context of software engineering education by means of a systematic mapping study. Second, we investigate how these game-related methods support specific knowledge areas from software engineering. By achieving these goals, we aim not only to characterize the state of the art on the use of game-related methods on software engineering education, but also to identify gaps and opportunities for further research. Method We carried out a systematic mapping study to identify primary studies which address the use, proposal or evaluation of games and their elements on software engineering education. We classified primary studies based on type of approaches, learning goals based on software engineering knowledge areas, and specific characteristics of each type of approach. Results We identified 156 primary studies, published between 1974 and June 2016. Most primary studies describe the use of serious games (86) and game development (57) for software engineering education, while Gamification is the least explored method (10). Learning goals of these studies and their development of skills are mostly related to the knowledge areas of “Software Process”, “Software Design”, and “Professional Practices”. Conclusions The use of games in software engineering education is not new. However, there are some knowledge areas where the use of games can still be further explored. Gamification is a new trend and existing research in the field is quite preliminary. We also noted a lack of standardization both in the definition of learning goals and in the classification of game-related methods. "
}
@article{Munir2017,
title = "A Theory of Openness for Software Engineering Tools in Software Organizations ",
journal = "Information and Software Technology ",
volume = "",
number = "",
pages = " - ",
year = "2017",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.12.008",
url = "https://www.sciencedirect.com/science/article/pii/S095058491730513X",
author = "Hussan Munir and Per Runeson and Krzysztof Wnuk",
keywords = "Open Innovation",
keywords = "Open Source Software",
keywords = "OSS tools",
keywords = "Openness",
keywords = "Theory creation ",
abstract = "Abstract Context. The increased use of Open Source Software (OSS) affects how software-intensive product development organizations (SIPDO) innovate and compete, moving them towards Open Innovation (OI). Specifically, software engineering tools have the potential for OI, but require better understanding regarding what to develop internally and what to acquire from outside the organization, and how to cooperate with potential competitors. Aim. This paper aims at synthesizing a theory of openness for software engineering tools in SIPDOs, that can be utilized by managers in defining more efficient strategies towards \{OSS\} communities. Method. We synthesize empirical evidence from a systematic mapping study, a case study, and a survey, using a narrative method. The synthesis method entails four steps: (1) Developing a preliminary synthesis, (2) Exploring the relationship between studies, (3) Assessing the validity of the synthesis, and (4) Theory formation. Result. We present a theory of openness for \{OSS\} tools in software engineering in relation to four constructs: (1) Strategy, (2) Triggers, (3) Outcomes, and (4) Level of openness. Conclusion. The theory reasons that openness provides opportunities to reduce the development cost and development time. Furthermore, \{OI\} positively impacts on the process and product innovation, but it requires investment by organizations in \{OSS\} communities. By betting on openness, organizations may be able to significantly increase their competitiveness. "
}
@article{daSilva2012216,
title = "Towards understanding the underlying structure of motivational factors for software engineers to guide the definition of motivational programs ",
journal = "Journal of Systems and Software ",
volume = "85",
number = "2",
pages = "216 - 226",
year = "2012",
note = "Special issue with selected papers from the 23rd Brazilian Symposium on Software Engineering ",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2010.12.017",
url = "https://www.sciencedirect.com/science/article/pii/S0164121210003390",
author = "Fabio Q.B. da Silva and A. César C. França",
keywords = "Motivation",
keywords = "People management",
keywords = "Software development",
keywords = "Empirical software engineering ",
abstract = "Aim In this article, factors influencing the motivation of software engineers is studied with the goal of guiding the definition of motivational programs. Method Using a set of 20 motivational factors compiled in a systematic literature review and a general theory of motivation, a survey questionnaire was created to evaluate the influence of these factors on individual motivation. Then, the questionnaire was applied on a semi-random sample of 176 software engineers from 20 software companies located in Recife-PE, Brazil. Results The survey results show the actual level of motivation for each motivator in the target population. Using principal component analysis on the values of all motivators, a five factor structure was identified and used to propose a guideline for the creation of motivational programs for software engineers. Conclusions The five factor structure provides an intuitive categorization for the set of variables and can be used to explain other motivational models presented in the literature. This contributes to a better understanding of motivation in software engineering. "
}
@article{Jadhav2009555,
title = "Evaluating and selecting software packages: A review ",
journal = "Information and Software Technology ",
volume = "51",
number = "3",
pages = "555 - 563",
year = "2009",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2008.09.003",
url = "https://www.sciencedirect.com/science/article/pii/S0950584908001262",
author = "Anil S. Jadhav and Rajendra M. Sonar",
keywords = "Software evaluation",
keywords = "Software selection",
keywords = "Evaluation criteria",
keywords = "Software selection tools ",
abstract = "Evaluating and selecting software packages that meet an organization’s requirements is a difficult software engineering process. Selection of a wrong software package can turn out to be costly and adversely affect business processes. The aim of this paper is to provide a basis to improve the process of evaluation and selection of the software packages. This paper reports a systematic review of papers published in journals and conference proceedings. The review investigates methodologies for selecting software packages, software evaluation techniques, software evaluation criteria, and systems that support decision makers in evaluating software packages. The key findings of the review are: (1) analytic hierarchy process has been widely used for evaluation of the software packages, (2) there is lack of a common list of generic software evaluation criteria and its meaning, and (3) there is need to develop a framework comprising of software selection methodology, evaluation technique, evaluation criteria, and system to assist decision makers in software selection. "
}
@article{Phillips2018150,
title = "An architecture, system engineering, and acquisition approach for space system software resiliency ",
journal = "Information and Software Technology ",
volume = "94",
number = "",
pages = "150 - 164",
year = "2018",
note = "",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2017.10.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584917300575",
author = "Dewanne M. Phillips and Thomas A. Mazzuchi and Shahram Sarkani",
keywords = "Software",
keywords = "Architecture",
keywords = "Resiliency",
keywords = "Systems engineering",
keywords = "Life cycle",
keywords = "Vulnerabilities",
keywords = "Threats",
keywords = "Cybersecurity ",
abstract = "AbstractContext Software-intensive space systems can harbor defects and vulnerabilities that may enable external adversaries or malicious insiders to disrupt or disable system functions, risking mission compromise or loss. Mitigating this risk demands a sustained focus on the security and resiliency of the system architecture including software, hardware, and other components. Objective In this paper we offer methodical approaches for improving space system resiliency through software architecture design, system engineering, and increased software security, thereby reducing the risk of latent software defects and vulnerabilities. Method We conducted a systematic review of existing architectural practices, standards, security and coding practices, various threats, defects, and vulnerabilities that impact space systems from hundreds of relevant publications and interviews of subject matter experts. We expanded on the system-level body of knowledge for resiliency and identified a new software architecture framework and acquisition methodology to improve the resiliency of space systems from a software perspective with an emphasis on the early phases of the systems engineering life cycle. This methodology involves seven steps: 1) Define technical resiliency requirements, 1a) Identify standards/policy for software resiliency, 2) Develop a request for proposal (RFP)/statement of work (SOW) for resilient space systems software, 3) Define software resiliency goals for space systems, 4) Establish software resiliency quality attributes, 5) Perform architectural tradeoffs and identify risks, 6) Conduct architecture assessments as part of the procurement process, and 7) Ascertain space system software architecture resiliency metrics. Results Data illustrates that software vulnerabilities can lead to opportunities for malicious cyber activities, which could degrade the space mission capability for its user community. Reducing the number of vulnerabilities by improving architecture and software system engineering practices can contribute to making space systems more resilient. Conclusion Since cyber-attacks [1] are enabled by shortfalls in software, robust software engineering practices and an architectural design are foundational to resiliency, which is a quality that allows the system to take a hit to a critical component and recover in a known, bounded, and generally acceptable period of time. To achieve software resiliency for space systems, acquirers and suppliers must identify relevant factors and systems engineering practices to apply across the life cycle, in software requirements analysis, architecture development, design, implementation, verification and validation, and maintenance phases. "
}
@article{Shahin2014161,
title = "A systematic review of software architecture visualization techniques ",
journal = "Journal of Systems and Software ",
volume = "94",
number = "",
pages = "161 - 185",
year = "2014",
note = "",
issn = "0164-1212",
doi = "https://doi.org/10.1016/j.jss.2014.03.071",
url = "https://www.sciencedirect.com/science/article/pii/S0164121214000831",
author = "Mojtaba Shahin and Peng Liang and Muhammad Ali Babar",
keywords = "Software architecture",
keywords = "Software architecture visualization",
keywords = "Visualization techniques ",
abstract = "AbstractContext Given the increased interest in using visualization techniques (VTs) to help communicate and understand software architecture (SA) of large scale complex systems, several \{VTs\} and tools have been reported to represent architectural elements (such as architecture design, architectural patterns, and architectural design decisions). However, there is no attempt to systematically review and classify the \{VTs\} and associated tools reported for SA, and how they have been assessed and applied. Objective This work aimed at systematically reviewing the literature on software architecture visualization to develop a classification of \{VTs\} in SA, analyze the level of reported evidence and the use of different \{VTs\} for representing \{SA\} in different application domains, and identify the gaps for future research in the area. Method We used systematic literature review (SLR) method of the evidence-based software engineering (EBSE) for reviewing the literature on \{VTs\} for SA. We used both manual and automatic search strategies for searching the relevant papers published between 1 February 1999 and 1 July 2011. Results We selected 53 papers from the initially retrieved 23,056 articles for data extraction, analysis, and synthesis based on pre-defined inclusion and exclusion criteria. The results from the data analysis enabled us to classify the identified \{VTs\} into four types based on the usage popularity: graph-based, notation-based, matrix-based, and metaphor-based VTs. The \{VTs\} in \{SA\} are mostly used for architecture recovery and architectural evolution activities. We have also identified ten purposes of using \{VTs\} in SA. Our results also revealed that \{VTs\} in \{SA\} have been applied to a wide range of application domains, among which “graphics software” and “distributed system” have received the most attention. Conclusion \{SA\} visualization has gained significant importance in understanding and evolving software-intensive systems. However, only a few \{VTs\} have been employed in industrial practice. This review has enabled us to identify the following areas for further research and improvement: (i) it is necessary to perform more research on applying visualization techniques in architectural analysis, architectural synthesis, architectural implementation, and architecture reuse activities; (ii) it is essential to pay more attention to use more objective evaluation methods (e.g., controlled experiment) for providing more convincing evidence to support the promised benefits of using \{VTs\} in SA; (iii) it is important to conduct industrial surveys for investigating how software architecture practitioners actually employ \{VTs\} in architecting process and what are the issues that hinder and prevent them from adopting \{VTs\} in SA. "
}
@article{Riņķevičs2013267,
title = "Equality in cumulative voting: A systematic review with an improvement proposal ",
journal = "Information and Software Technology ",
volume = "55",
number = "2",
pages = "267 - 287",
year = "2013",
note = "Special Section: Component-Based Software Engineering (CBSE), 2011 ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2012.08.004",
url = "https://www.sciencedirect.com/science/article/pii/S0950584912001589",
author = "K. Riņķevičs and R. Torkar",
keywords = "Cumulative voting",
keywords = "Prioritization",
keywords = "Requirements engineering",
keywords = "Compositional data",
keywords = "Log-ratio ",
abstract = "Context Prioritization is an essential part of requirements engineering, software release planning and many other software engineering disciplines. Cumulative Voting (CV) is known as a relatively simple method for prioritizing requirements on a ratio scale. Historically, \{CV\} has been applied in decision-making in government elections, corporate governance, and forestry. However, \{CV\} prioritization results are of a special type of data—compositional data. Objectives The purpose of this study is to aid decision-making by collecting knowledge on the empirical use of \{CV\} and develop a method for detecting prioritization items with equal priority. Methods We present a systematic literature review of \{CV\} and \{CV\} analysis methods. The review is based on searching electronic databases and snowball sampling of the found primary studies. Relevant studies are selected based on titles, abstracts, and full text inspection. Additionally, we propose Equality of Cumulative Votes (ECVs)—a \{CV\} result analysis method that identifies prioritization items with equal priority. Results \{CV\} has been used in not only requirements prioritization and release planning but also in e.g. software process improvement, change impact analysis and model driven software development. The review presents a collection of state of the practice studies and \{CV\} result analysis methods. In the end, \{ECV\} was applied to 27 prioritization cases from 14 studies and identified nine groups of equal items in three studies. Conclusions We believe that the analysis of the collected studies and the \{CV\} result analysis methods can help in the adoption of \{CV\} prioritization method. The evaluation of \{ECV\} indicates that it is able to detect prioritization items with equal priority and thus provide the practitioner with a more fine-grained analysis. "
}
@article{Kampenes200971,
title = "A systematic review of quasi-experiments in software engineering ",
journal = "Information and Software Technology ",
volume = "51",
number = "1",
pages = "71 - 82",
year = "2009",
note = "Special Section - Most Cited Articles in 2002 and Regular Research Papers ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2008.04.006",
url = "https://www.sciencedirect.com/science/article/pii/S0950584908000670",
author = "Vigdis By Kampenes and Tore Dybå and Jo E. Hannay and Dag I. K. Sjøberg",
keywords = "Quasi-experiments",
keywords = "Randomization",
keywords = "Field experiments",
keywords = "Empirical software engineering",
keywords = "Selection bias",
keywords = "Effect size ",
abstract = "Background: Experiments in which study units are assigned to experimental groups nonrandomly are called quasi-experiments. They allow investigations of cause–effect relations in settings in which randomization is inappropriate, impractical, or too costly. Problem outline: The procedure by which the nonrandom assignments are made might result in selection bias and other related internal validity problems. Selection bias is a systematic (not happening by chance) pre-experimental difference between the groups that could influence the results. By detecting the cause of the selection bias, and designing and analyzing the experiments accordingly, the effect of the bias may be reduced or eliminated. Research method: To investigate how quasi-experiments are performed in software engineering (SE), we conducted a systematic review of the experiments published in nine major \{SE\} journals and three conference proceedings in the decade 1993–2002. Results: Among the 113 experiments detected, 35% were quasi-experiments. In addition to field experiments, we found several applications for quasi-experiments in SE. However, there seems to be little awareness of the precise nature of quasi-experiments and the potential for selection bias in them. The term “quasi-experiment” was used in only 10% of the articles reporting quasi-experiments; only half of the quasi-experiments measured a pretest score to control for selection bias, and only 8% reported a threat of selection bias. On average, larger effect sizes were seen in randomized than in quasi-experiments, which might be due to selection bias in the quasi-experiments. Conclusion: We conclude that quasi-experimentation is useful in many settings in SE, but their design and analysis must be improved (in ways described in this paper), to ensure that inferences made from this kind of experiment are valid. "
}
@article{Höst2011616,
title = "A systematic review of research on open source software in commercial software product development ",
journal = "Information and Software Technology ",
volume = "53",
number = "6",
pages = "616 - 624",
year = "2011",
note = "Special Section: Best papers from the \{APSECBest\} papers from the \{APSEC\} ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2010.12.009",
url = "https://www.sciencedirect.com/science/article/pii/S0950584910002259",
author = "Martin Höst and Alma Oručević-Alagić",
keywords = "Open source software",
keywords = "Proprietary",
keywords = "Commercial",
keywords = "Component based software engineering",
keywords = "Business models ",
abstract = "Context The popularity of the open source software development in the last decade, has brought about an increased interest from the industry on how to use open source components, participate in the open source community, build business models around this type of software development, and learn more about open source development methodologies. There is a need to understand the results of research in this area. Objective Since there is a need to understand conducted research, the aim of this study is to summarize the findings of research that has ben carried out on usage of open source components and development methodologies by the industry, as well as companies’ participation in the open source community. Method Systematic review through searches in library databases and manual identification of articles from the open source conference. The search was first carried out in May 2009 and then once again in May 2010. Results In 2009, 237 articles were first found, from which 19 were selected based on content and quality, and in 2010, 76 new articles were found from which four were selected. Twenty three articles were identified in total. Conclusions The articles could be divided into four categories: open source as part of component based software engineering, business models with open source in commercial organization, company participation in open source development communities, and usage of open source processes within a company. "
}
@article{Edgar2014615,
title = "State of the Art in the Research of Formal Verification ",
journal = "Ingeniería, Investigación y Tecnología ",
volume = "15",
number = "4",
pages = "615 - 623",
year = "2014",
note = "",
issn = "1405-7743",
doi = "https://doi.org/10.1016/S1405-7743(14)70659-6",
url = "https://www.sciencedirect.com/science/article/pii/S1405774314706596",
author = "Serna-M. Edgar and Morales-V. David",
keywords = "formal verification",
keywords = "formal methods",
keywords = "software engineering",
keywords = "engineering techniques",
keywords = "research approaches",
keywords = "verificación formal",
keywords = "métodos formales",
keywords = "ingeniería de software",
keywords = "técnicas de ingenieréa",
keywords = "enfoques de investigación ",
abstract = "Abstract In recent years research in formal verification of hardware and software has reached important progresses in the development of methodologies and tools to meet the increasing complexity of systems. The explicit role of Formal Verification is to find errors and to improve the reliability on the accuracy of system design, which implies a challenge for software engineering of this century. The purpose of this research is to perform a systematic review of the literature to establish the state of the art of research in formal verification during the last 10 years and to identify the approaches, methods, techniques and methodologies used, as well as the intensity of those research activities. During the process it was found that research in this field has doubled since 2005, and that the mean value of researches conducted year after year remains the same and that prevail the application in control and interaction systems. Additionally it was found that, the case study is the most used method and that empirical research is the most applied type. "
}
@article{Adam201257,
title = "Building crop models within different crop modelling frameworks ",
journal = "Agricultural Systems ",
volume = "113",
number = "",
pages = "57 - 63",
year = "2012",
note = "",
issn = "0308-521X",
doi = "https://doi.org/10.1016/j.agsy.2012.07.010",
url = "https://www.sciencedirect.com/science/article/pii/S0308521X12001229",
author = "M. Adam and M. Corbeels and P.A. Leffelaar and H. Van Keulen and J. Wery and F. Ewert",
keywords = "Model structure",
keywords = "Uncertainty",
keywords = "Software design patterns",
keywords = "Good modelling practices",
keywords = "Crop growth and development ",
abstract = "Modular frameworks for crop modelling have evolved through simultaneous progress in crop science and software development but differences among these frameworks exist which are not well understood, resulting in potential misuse for crop modelling. In this paper we review differences and similarities among different developed frameworks and identify some implications for crop modelling. We consider three modelling frameworks currently used for crop modelling: \{CROSPAL\} (CROp Simulator: Picking and Assembling Libraries), \{APES\} (Agricultural Production and Externalities Simulator) and \{APSIM\} (Agricultural Production Systems sIMulator). The frameworks are implemented differently and they provide more or less flexibility and guidance, to facilitate assembly of crop model from model components. We underline the importance of systematic approaches to facilitate the selection of appropriate model structure and derive suggestions to facilitate it. We particularly stress the need for better documentation of the underlying assumptions of the modules on simulated processes and on the criteria applied in the selection of these modules for a particular simulation objective. Such documentation should help to point out the sources of uncertainties associated with the development of crop models and to reinforce the role of the crop modeller as an intermediary between the software engineer, coding the modules, and the end users, agronomists or crop physiologists using the model for a specific objective. Finally, the key contributions of modelling frameworks in the crop modelling domain are discussed and we draw conclusions for the prospects of such frameworks in the crop modelling field which should continue to reside on the principles of systems analysis but combined with up-to-date advances in software engineering techniques. "
}
@article{Laitenberger1997781,
title = "Perspective-based reading of code documents at Robert Bosch GmbH ",
journal = "Information and Software Technology ",
volume = "39",
number = "11",
pages = "781 - 791",
year = "1997",
note = "Evaluation and Assessment in Software Engineering ",
issn = "0950-5849",
doi = "https://doi.org/10.1016/S0950-5849(97)00030-X",
url = "https://www.sciencedirect.com/science/article/pii/S095058499700030X",
author = "Oliver Laitenberger and Jean-Marc DeBaud",
keywords = "Quality assessment",
keywords = "Defect detection",
keywords = "Experimentation",
keywords = "Inspection",
keywords = "Perspective-based reading ",
abstract = "Despite dramatic changes in software development in the two decades since the term software engineering was coined, software quality deficiencies and cost overruns continue to afflict the software industry. Inspections, developed at \{IBM\} by Fagan in the early 1970s [1], can be used to improve upon these problems because they allow the detection and removal of defects after each phase of the software development process. But, in most published inspection processes, individuals performing defect detection are not systematically supported. There, defect detection depends heavily upon factors like chance or experience. Further, there is an ongoing debate in the literature whether or not defect detection is more effective when performed as a group activity and hence should be conducted in meetings [5,11,13,14]. In this article we introduce Perspective-based Reading (PBR) for code documents, a systematic technique to support individual defect detection. \{PBR\} offers guidance to individual inspectors for defect detection. This guidance is embodied within perspective-based algorithmic scenarios which makes individual defect detection independent of experience. To test this assumption, we tailored and introduced \{PBR\} in the inspection process at Robert Bosch GmbH. We conducted two training sessions in the form of a 2 × 3 fractional-factorial experiment in which 11 professional software developers reviewed code documents from three different perspectives. The experimental results are: (1) Perspectivebased Reading and the type of document have an influence on individual defect detection, (2) multi-individual inspection meetings were not very useful to detect defects, (3) the overlap of detected defects among inspectors using different perspectives is low, and (4) there are no significant differences with respect to defect detection between inspectors having experiences in the programming language and/or the application domain and those that do not. "
}

